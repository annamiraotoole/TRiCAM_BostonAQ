{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from statsmodels.tools import add_constant\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF, ConstantKernel as C\n",
    "import statsmodels.api as sm\n",
    "import pickle\n",
    "import os\n",
    "from sklearn import preprocessing\n",
    "sns.set(style=\"ticks\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "no2 = pd.read_csv(\"merged_no2weather.csv\")\n",
    "so2 = pd.read_csv(\"merged_so2weather.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#scale data\n",
    "del no2[\"Latitude\"]\n",
    "del no2[\"Longitude\"]\n",
    "del so2[\"Latitude\"]\n",
    "del so2[\"Longitude\"]\n",
    "\n",
    "no2_scaled = no2.iloc[:, 3:]\n",
    "no2_scaled = preprocessing.minmax_scale(no2_scaled)\n",
    "no2_scaled = pd.DataFrame(no2_scaled)\n",
    "add = no2.iloc[:, :3]\n",
    "no2_scaled = add.join(no2_scaled)\n",
    "cols = list(no2.columns)\n",
    "no2_scaled.columns = cols\n",
    "\n",
    "#splits train, test sets\n",
    "train_no2, test_no2 = train_test_split(no2_scaled, test_size=.30, random_state=0)\n",
    "#Scales y data (ppm values)\n",
    "y_train_no2 = train_no2['ppm'].values * 100\n",
    "y_test_no2 = test_no2['ppm'].values * 100\n",
    "test_no2 = test_no2.iloc[:, 3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#scale data\n",
    "so2_scaled = so2.iloc[:, 3:]\n",
    "so2_scaled = preprocessing.minmax_scale(so2_scaled)\n",
    "so2_scaled = pd.DataFrame(so2_scaled)\n",
    "add = so2.iloc[:, :3]\n",
    "so2_scaled = add.join(so2_scaled)\n",
    "cols = list(so2.columns)\n",
    "so2_scaled.columns = cols\n",
    "\n",
    "#splits train, test sets\n",
    "train_so2, test_so2 = train_test_split(so2_scaled, test_size=.30, random_state=0)\n",
    "#Scales y data (ppm values)\n",
    "y_train_so2 = train_so2['ppm'].values * 100\n",
    "y_test_so2 = test_so2['ppm'].values * 100\n",
    "test_so2 = test_so2.iloc[:, 3:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "'''Method that takes in a list of all the predictors left in the model, and the model, \n",
    "spits out the lowest p valued predictor and lowest p value'''\n",
    "def find_low_p(all_preds, model_OLS):\n",
    "    #initiates lowest p value\n",
    "    maxp = max(model_OLS.pvalues[1:])  \n",
    "    index = list(model_OLS.pvalues[1:]).index(maxp)\n",
    "    lowestlu = all_preds[index]\n",
    "\n",
    "    return maxp , lowestlu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"Input: y data set, list of predictor variables\n",
    "Action: X data set formed, runs a MLR through data set, computes pvalue, deletes predictor with least pvalue\n",
    "returns: models - one for each new data set created after deleting\n",
    "\"\"\"\n",
    "def backwards_var_sel(y, all_predictors, train):\n",
    "    models = [] #to hold all the models\n",
    "    x = train[all_predictors].values\n",
    "    x = add_constant(x, has_constant='add')\n",
    "    indices = []\n",
    "    copy = all_predictors\n",
    "\n",
    "    for i in range(len(copy)):\n",
    "        #fit a MLR to data set\n",
    "        OLS_model = sm.OLS(y, x).fit()\n",
    "\n",
    "        #finds lowest pvalue and index of lowest pvalue, excluding constant term\n",
    "\n",
    "        maxp, lowestlu = find_low_p(all_predictors, OLS_model)\n",
    "        #removes variable with lowest p value\n",
    "        index_td = copy.index(lowestlu)\n",
    "        indices.append(index_td)\n",
    "        index = all_predictors.index(lowestlu)\n",
    "        all_predictors = all_predictors[:index] + all_predictors[index+1 :]\n",
    "        \n",
    "        #updates list of x values, not including variable with lowest pvalue\n",
    "        x = train[all_predictors].values\n",
    "        x = add_constant(x, prepend=True)\n",
    "        #save new model in a list\n",
    "        models.append(OLS_model)\n",
    "        \n",
    "        \n",
    "    return models, indices\n",
    "\n",
    "predictors = ['forest',\n",
    "       'open_land', 'water', 'wetland', 'transitional',\n",
    "       'urban_public_institution', 'commercial', 'transportation', 'crop_land',\n",
    "       'medium_density_residential', 'industrial', \n",
    "       'outdoor_temperature', 'solar_radiation',\n",
    "       'wind_speed_resultant']\n",
    "\n",
    "#models, index_ls = backwards_var_sel(y_train_no2, predictors, train_no2)\n",
    "models, index_ls = backwards_var_sel(y_train_so2, predictors, train_so2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['commercial', 'transportation', 'medium_density_residential',\n",
       "       'industrial', 'solar_radiation'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_models = []\n",
    "index_of_model = []\n",
    "for i in range(len(models)):\n",
    "    if np.average(models[i].pvalues[1:]) < .005:\n",
    "        best_models.append(models[i])\n",
    "        #print(np.average(models[i].pvalues[1:]))\n",
    "        index_of_model.append(i)\n",
    "model2_pos = index_of_model[0]\n",
    "#must subtract 1. index ls tells what column to remove, but models list includes the model with no column removed at all\n",
    "new_index_list = index_ls[:model2_pos]\n",
    "test1 = test_so2.drop(test_so2.columns[new_index_list], axis=1)\n",
    "best_models[0].summary()\n",
    "test1.columns\n",
    "#test1 = add_constant(test1, has_constant = \"add\")\n",
    "#np.mean((best_models[0].predict(test1)-y_test_so2)**2)\n",
    "##linmodel = LinearRegression(fit_intercept=True)\n",
    "#linmodel.fit(test1,y_test_so2)\n",
    "#linmodel.score(test1, y_test_so2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['transportation', 'industrial', 'solar_radiation'], dtype='object')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_models = []\n",
    "index_of_model = []\n",
    "for i in range(len(models)):\n",
    "    if np.average(models[i].pvalues[1:]) < .00001:\n",
    "        best_models.append(models[i])\n",
    "        #print(np.average(models[i].pvalues[1:]))\n",
    "        index_of_model.append(i)\n",
    "model2_pos = index_of_model[0]\n",
    "#must subtract 1. index ls tells what column to remove, but models list includes the model with no column removed at all\n",
    "new_index_list = index_ls[:model2_pos]\n",
    "test1 = test_no2.drop(test_no2.columns[new_index_list], axis=1)\n",
    "best_models[0].summary()\n",
    "#test1 = add_constant(test1)\n",
    "#np.mean((best_models[0].predict(test1)-y_test_no2)**2)\n",
    "#linmodel = LinearRegression(fit_intercept=True)\n",
    "#linmodel.fit(test1,y_test_no2)\n",
    "#linmodel.score(test1, y_test_no2)\n",
    "test1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predictors = ['forest',\n",
    "       'open_land', 'water', 'wetland', 'transitional',\n",
    "       'urban_public_institution', 'commercial', 'transportation', 'crop_land',\n",
    "       'medium_density_residential', 'industrial',\n",
    "       'outdoor_temperature', 'solar_radiation',\n",
    "       'wind_speed_resultant']\n",
    "\n",
    "\"\"\"Input: y data set, list of predictor variables\n",
    "Action: X data set formed, runs a MLR through data set, computes AIC, deletes predictor with maximum AIC\n",
    "returns: models - list of remaining predictors after each iteration\n",
    "\"\"\"\n",
    "def backwards_var_sel_aic(y, all_predictors, train):\n",
    "    preds = [] #to hold all the list of predictors\n",
    "    copy = all_predictors #keeps copy of full predictors list #holds AIC values for each iteration\n",
    "    models = []\n",
    "    indices = []\n",
    "    for j in range(len(copy)):\n",
    "        t = all_predictors\n",
    "        AIC = []\n",
    "        for i in range(len(t)):\n",
    "            #removes one predictor in each iteration\n",
    "            predictors = all_predictors[:i] + all_predictors[i+1 :]\n",
    "            #print(predictors)\n",
    "            #train and fit a model on those predictors\n",
    "            x = train[predictors].values\n",
    "            x = add_constant(x, has_constant='add')\n",
    "            OLS_model = sm.OLS(y, x).fit()\n",
    "\n",
    "            #append AIC value to AIC list for each iteration\n",
    "            AIC.append(OLS_model.aic)\n",
    "        #finds the largest AIC and the index at which it exists\n",
    "        worstAIC = max(AIC)\n",
    "        index = AIC.index(max(AIC))\n",
    "        worstLU = all_predictors[index]\n",
    "        indices.append(copy.index(worstLU))\n",
    "        #reassign all_predictors to a new list with the predictor corresponding to the worst AIC removed\n",
    "        all_predictors = all_predictors[:index] + all_predictors[index+1 :]\n",
    "        #append a list of the remaining predictors to the models list\n",
    "        preds.append(all_predictors)\n",
    "        models.append(OLS_model)\n",
    "        \n",
    "    return models, indices, preds\n",
    "\n",
    "\n",
    "models, indices, predicts = backwards_var_sel_aic(y_train_so2, predictors, train_so2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.0187404 ,  0.01498904,  0.01132031, ...,  0.00540185,\n",
       "        0.00540185,  0.00540185])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# relevant for \n",
    "best_models = []\n",
    "for i in range(len(models)):\n",
    "    #find all models where the average pvalue is less than 0.09\n",
    "    best_models.append(models[i].aic)\n",
    "m = min(best_models)\n",
    "#finds minimum aic among each model\n",
    "#gets the index of every instance where the minimum AIC occurs\n",
    "index_of_model = best_models.index(m)\n",
    "models[0].summary()\n",
    "test2 = test_no2.loc[:, predicts[0]]\n",
    "test2 = add_constant(test2, has_constant=\"add\")\n",
    "#test2[\"const\"] = np.repeat(1, len(test2.index))\n",
    "no2preds = test2.columns\n",
    "\n",
    "boston = pd.read_csv(\"final_boston.csv\")\n",
    "np.mean((models[0].predict(test2)-y_test_no2)**2)\n",
    "linmodel = LinearRegression(fit_intercept=True)\n",
    "linmodel.fit(test2,y_test_no2)\n",
    "linmodel.score(test2, y_test_no2)\n",
    "\n",
    "finaltest = boston[list(no2preds)[1:]]\n",
    "\n",
    "finaltest = preprocessing.minmax_scale(finaltest)\n",
    "#turns array back into dataframe\n",
    "finaltest = pd.DataFrame(finaltest)\n",
    "finaltest = add_constant(finaltest, has_constant=\"add\")\n",
    "\n",
    "boston_aic_preds = models[0].predict(finaltest)/100\n",
    "def parse_str(str_edit):\n",
    "#   print str_edit\n",
    "    str_edit = str_edit.replace('[', '')\n",
    "    str_edit = str_edit.replace('(', '')\n",
    "    str_edit = str_edit.replace(']', '')\n",
    "    str_edit = str_edit.replace(')', '')\n",
    "    str_edit = str_edit.replace(',', '')\n",
    "    list = str_edit.split(' ')\n",
    "#   print list\n",
    "    return [[np.float64(list[0]), np.float64(list[1])], [np.float64(list[2]), np.float64(list[3])],\n",
    "      [np.float64(list[4]), np.float64(list[5])], [np.float64(list[6]), np.float64(list[7])]]\n",
    "\n",
    "loc = []\n",
    "for i in boston[\"Site\"]:\n",
    "    loc.append(parse_str(i))\n",
    "lats, longs = [], []\n",
    "for i in np.arange(len(loc)):\n",
    "    lats.append((loc[i][0][0], loc[i][0][1], boston_aic_preds[i]))\n",
    "    #longs.append(i[0][1])\n",
    "w = pd.DataFrame(pd.Series(lats))\n",
    "w.to_csv(\"boston_no2_LUR_preds.csv\", index=False)\n",
    "w.to_json(\"boston_no2_LUR_preds.json\")\n",
    "boston_aic_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.613</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.608</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   121.2</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Fri, 04 Aug 2017</td> <th>  Prob (F-statistic):</th> <td>1.45e-194</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>13:43:15</td>     <th>  Log-Likelihood:    </th> <td> -1105.9</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1009</td>      <th>  AIC:               </th> <td>   2240.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   995</td>      <th>  BIC:               </th> <td>   2309.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    13</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th> <th>[95.0% Conf. Int.]</th> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td>    0.1694</td> <td>    0.154</td> <td>    1.099</td> <td> 0.272</td> <td>   -0.133     0.472</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>   -1.0584</td> <td>    0.372</td> <td>   -2.845</td> <td> 0.005</td> <td>   -1.788    -0.328</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>   -1.6311</td> <td>    0.380</td> <td>   -4.294</td> <td> 0.000</td> <td>   -2.376    -0.886</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>    0.3065</td> <td>    0.517</td> <td>    0.593</td> <td> 0.554</td> <td>   -0.708     1.321</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td>   -1.5820</td> <td>    0.737</td> <td>   -2.146</td> <td> 0.032</td> <td>   -3.029    -0.135</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>    <td>   -1.7591</td> <td>    0.672</td> <td>   -2.618</td> <td> 0.009</td> <td>   -3.078    -0.440</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>    <td>   -0.5411</td> <td>    0.272</td> <td>   -1.990</td> <td> 0.047</td> <td>   -1.075    -0.007</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>    <td>    0.6120</td> <td>    0.146</td> <td>    4.187</td> <td> 0.000</td> <td>    0.325     0.899</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>    <td>    2.8961</td> <td>    0.299</td> <td>    9.696</td> <td> 0.000</td> <td>    2.310     3.482</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>    <td>   -1.0400</td> <td>    0.279</td> <td>   -3.731</td> <td> 0.000</td> <td>   -1.587    -0.493</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>   <td>    1.2477</td> <td>    0.239</td> <td>    5.227</td> <td> 0.000</td> <td>    0.779     1.716</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>   <td>    2.1405</td> <td>    0.360</td> <td>    5.950</td> <td> 0.000</td> <td>    1.435     2.846</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>   <td>    2.5088</td> <td>    0.232</td> <td>   10.834</td> <td> 0.000</td> <td>    2.054     2.963</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>   <td>    0.4251</td> <td>    0.171</td> <td>    2.485</td> <td> 0.013</td> <td>    0.089     0.761</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>301.407</td> <th>  Durbin-Watson:     </th> <td>   1.998</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>1495.116</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.293</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 8.373</td>  <th>  Cond. No.          </th> <td>    39.6</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.613\n",
       "Model:                            OLS   Adj. R-squared:                  0.608\n",
       "Method:                 Least Squares   F-statistic:                     121.2\n",
       "Date:                Fri, 04 Aug 2017   Prob (F-statistic):          1.45e-194\n",
       "Time:                        13:43:15   Log-Likelihood:                -1105.9\n",
       "No. Observations:                1009   AIC:                             2240.\n",
       "Df Residuals:                     995   BIC:                             2309.\n",
       "Df Model:                          13                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [95.0% Conf. Int.]\n",
       "------------------------------------------------------------------------------\n",
       "const          0.1694      0.154      1.099      0.272        -0.133     0.472\n",
       "x1            -1.0584      0.372     -2.845      0.005        -1.788    -0.328\n",
       "x2            -1.6311      0.380     -4.294      0.000        -2.376    -0.886\n",
       "x3             0.3065      0.517      0.593      0.554        -0.708     1.321\n",
       "x4            -1.5820      0.737     -2.146      0.032        -3.029    -0.135\n",
       "x5            -1.7591      0.672     -2.618      0.009        -3.078    -0.440\n",
       "x6            -0.5411      0.272     -1.990      0.047        -1.075    -0.007\n",
       "x7             0.6120      0.146      4.187      0.000         0.325     0.899\n",
       "x8             2.8961      0.299      9.696      0.000         2.310     3.482\n",
       "x9            -1.0400      0.279     -3.731      0.000        -1.587    -0.493\n",
       "x10            1.2477      0.239      5.227      0.000         0.779     1.716\n",
       "x11            2.1405      0.360      5.950      0.000         1.435     2.846\n",
       "x12            2.5088      0.232     10.834      0.000         2.054     2.963\n",
       "x13            0.4251      0.171      2.485      0.013         0.089     0.761\n",
       "==============================================================================\n",
       "Omnibus:                      301.407   Durbin-Watson:                   1.998\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             1495.116\n",
       "Skew:                           1.293   Prob(JB):                         0.00\n",
       "Kurtosis:                       8.373   Cond. No.                         39.6\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# relevant for \n",
    "best_models = []\n",
    "for i in range(len(models)):\n",
    "    #find all models where the average pvalue is less than 0.09\n",
    "    best_models.append(models[i].aic)\n",
    "m = min(best_models)\n",
    "#finds minimum aic among each model\n",
    "#gets the index of every instance where the minimum AIC occurs\n",
    "index_of_model = best_models.index(m)\n",
    "models[0].summary()\n",
    "\n",
    "#test2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
