{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn as sk\n",
    "from sklearn import mixture\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from statsmodels.tools import add_constant\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.gaussian_process.kernels import ConstantKernel as C\n",
    "from sklearn.gaussian_process.kernels import Matern, WhiteKernel, RationalQuadratic, DotProduct\n",
    "import statsmodels.api as sm\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "\n",
    "# import tensorflow as tf\n",
    "# import GPflow\n",
    "# import george\n",
    "# george.__version__\n",
    "# from george import kernels\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set(style=\"ticks\")\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Define functions needed for Gaussian process model </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_filenames(folderpath):\n",
    "    filenames = os.listdir(folderpath)\n",
    "    return filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Reading CO2 hourly Data for 6/19 in Boston\"\"\"\n",
    "\n",
    "def read_csv_file(file):\n",
    "    df = pd.read_csv(file)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Reads in multiple csv files given list of filenames/paths\n",
    "Returns dataframe containing combined concatenated file contents\n",
    "\"\"\"\n",
    "\n",
    "def read_multiple_csvs(filename_list, local_path):\n",
    "\n",
    "    DFlist = []\n",
    "\n",
    "    for i in range(0,6):\n",
    "        DF = pd.read_csv(local_path + filename_list[i], engine='python')\n",
    "        # hold = DF[\"Sample Collection Start Time\"]\n",
    "        # DF[\"Sample Collection Start Time\"] = hold + 24*i\n",
    "        DFlist.append(DF)\n",
    "        \n",
    "    big_dataframe = pd.concat(DFlist)\n",
    "    \n",
    "    return big_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Cleans the times to a parsable format\"\"\"\n",
    "\n",
    "def clean_time(col_name):\n",
    "    times = []\n",
    "    time = list(df[col_name])\n",
    "    for i in range(len(time)):\n",
    "        times.append(float(time[i][:2]))\n",
    "    df[col_name] = times #could cause error\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Cleans the times to a parsable format for multiple days in a row\"\"\"\n",
    "def clean_time_multiple(DF, col_name):\n",
    "    \n",
    "    times = []\n",
    "    time = list(DF[col_name])\n",
    "    \n",
    "    prev_T = float(time[0][:2])\n",
    "    day = 0\n",
    "    \n",
    "    for i in range(len(time)):\n",
    "        T = float(time[i][:2])\n",
    "        if prev_T > T:\n",
    "            day += 1\n",
    "        times.append(T + day*24)\n",
    "        prev_T = T\n",
    "    \n",
    "    DF[col_name] = times\n",
    "    \n",
    "    return DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Splits dataframe into train and test data\"\"\"\n",
    "def split_train_test(df):\n",
    "    train, test = train_test_split(df, test_size=.30, random_state=0)\n",
    "    x_train = train[\"Sample Collection Start Time\"]\n",
    "    y_train = train[\"Measure Value\"]\n",
    "    x_test = test[\"Sample Collection Start Time\"]\n",
    "    y_test = test[\"Measure Value\"]\n",
    "    return x_train, y_train, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Plots level of air pollutant with respect to time for x train and y train\"\"\"\n",
    "def plot_original(x_train, y_train):\n",
    "    plt.scatter(x_train, y_train)\n",
    "    plt.ylabel(\"Measure Value\")\n",
    "    plt.xlabel(\"Time Occurred\")\n",
    "    plt.title(\"Boston CO2 level on 6/19\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Creates Gaussian model, computs r squarred, MSE and log liklihood\n",
    "Given x_train, y_train, x_test, and y_test data, and numerical alpha value\n",
    "Prints train and test R^2\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def simple_gaussian(x_train, y_train, x_test, y_test, alpha):\n",
    "    \n",
    "    train_size = x_train.shape[0]\n",
    "    test_size = x_test.shape[0]\n",
    "    \n",
    "    kern = RBF(length_scale = 1)\n",
    "    \n",
    "    gp = GaussianProcessRegressor(kernel=kern, alpha=alpha, optimizer='fmin_l_bfgs_b', n_restarts_optimizer=1, normalize_y=False, copy_X_train=False, random_state=None)\n",
    "    gp.fit(x_train.reshape(train_size, 1), y_train.reshape(train_size, 1))\n",
    "\n",
    "    y_train_pred, sigma_train = gp.predict(x_train.reshape(train_size, 1), return_std=True)\n",
    "    y_test_pred, sigma_test = gp.predict(x_test.reshape(test_size, 1), return_std=True)\n",
    "\n",
    "    # get R^2\n",
    "    r2 = gp.score(x_train.reshape(train_size, 1), y_train.reshape(train_size, 1))\n",
    "    r2_t = gp.score(x_test.reshape(test_size, 1), y_test.reshape(test_size, 1))\n",
    "\n",
    "    # get MSE measurements\n",
    "    MSE_test = np.mean((y_test_pred - y_test.reshape(test_size, 1))**2)\n",
    "    MSE_train = np.mean((y_train_pred - y_train.reshape(train_size, 1))**2)\n",
    "\n",
    "    # get log likelihood\n",
    "    t = gp.log_marginal_likelihood()\n",
    "\n",
    "    # calculate AIC\n",
    "    AIC = 2*len(x_test) - 2*np.log(-t)\n",
    "    \n",
    "    # print R^2 values\n",
    "    print('mean squared error of train data with model = ' + str(MSE_train))\n",
    "    print('mean squared error of test data with model = ' + str(MSE_test))\n",
    "    print('Akaike information criterion = ' + str(AIC))\n",
    "    print('log likelihood of model = ' + str(t))\n",
    "    print('training R^2 value = ' + str(r2))\n",
    "    print('testing R^2 value = ' + str(r2_t))\n",
    "    \n",
    "    return y_train_pred, y_test_pred, gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Plots predicted y values for testing set\"\"\"\n",
    "def plot_predictions(x_test, y_test, y_test_pred, x_label, y_label):\n",
    "    plt.figure(figsize=(13,8))\n",
    "    plt.plot(x_test, y_test, \".\", color=\"r\",)\n",
    "    plt.scatter(x_test, y_test_pred)\n",
    "    plt.xlabel(x_label)\n",
    "    plt.title(y_label)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Kaela and Annamira's Gaussian models: </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Gaussian process (six days in a row) </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pollutants = ['CO', 'SO', 'NO', 'OZO', 'PM']\n",
    "local_path = 'Boston_AQ_Hourly/'\n",
    "\n",
    "alphas = [0.000888, 0.00000001, 0.000001, 0.00001, 0.000588]\n",
    "\n",
    "x_label = 'Time'\n",
    "y_labels = pollutants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for i in range(0,5):\n",
    "\n",
    "    filenames = get_filenames(local_path + pol + '/')\n",
    "\n",
    "    DF = read_multiple_csvs(filenames, local_path + pol + '/')\n",
    "\n",
    "    DF = clean_time_multiple(DF, 'Sample Collection Start Time')\n",
    "    \n",
    "    '''\n",
    "    file = open('appended' + pol + '.csv', 'w')\n",
    "    DF.to_csv(file)\n",
    "    file.close()\n",
    "    '''\n",
    "\n",
    "    x_train, y_train, x_test, y_test = split_train_test(DF)\n",
    "\n",
    "    y_train_pred, y_test_pred, gp = simple_gaussian(x_train, y_train, x_test, y_test, alphas[i])\n",
    "\n",
    "    plot_predictions(x_test, y_test, y_test_pred, x_label, y_labels[i])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
