{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed `CDLL(/Library/Frameworks/GEOS.framework/Versions/Current/GEOS)`\n",
      "Failed `CDLL(/opt/local/lib/libgeos_c.dylib)`\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point\n",
    "from shapely.geometry.polygon import Polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23,)\n",
      "(23,)\n"
     ]
    }
   ],
   "source": [
    "#1st - read in the csv file\n",
    "data = pd.read_csv(\"small_scale_data.csv\")\n",
    "#pull out only the shape column which are all in string format\n",
    "shape_col = data[\"SHAPE\"]\n",
    "usage_col = data[\"LU05_DESC\"]\n",
    "print (shape_col.shape)\n",
    "print (usage_col.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#create multigon finder and deal with it separately, then .apply(get_coord)\n",
    "def find_multi(row):\n",
    "    found = False\n",
    "    if '), (' in row:\n",
    "        found = True\n",
    "    return found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#PREP FUNCTION COMES BEFORE FEEDING INTO THE APPROPRIATE MULTI/POLY FUNCTION TO MAKE DATA UNIFORM FORMAT\n",
    "def prep_row(row):\n",
    "    cleaned = row[16:-3]\n",
    "    return cleaned # should look like 'lon lat, lon lat,...), (lon lat, lon lat...), (.....'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#GET_POLY FUNCTION CLEANS AND DEALS WITH SINGLE POLYGONS\n",
    "#MULTIPOLYGON ROWS GET FED INTO GET_MULTI, WHICH THEN UTILIZES THIS FUNCTION WITHIN IT\n",
    "def get_poly(data):\n",
    "    # split the string into elements of a list by each comma\n",
    "    vertex = data.split(\",\")\n",
    "    # strip white spaces from each element\n",
    "    vertex = [item.strip() for item in vertex ]\n",
    "    # format the elements from 'latitude longitude' string to (latitude, longitude) floats\n",
    "    vertex = [(float(item.split(\" \")[0]) ,float(item.split(\" \")[1])) for item in vertex]\n",
    "    return (np.asarray(vertex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GET_MULTI DEALS WITH MULTIPOLYGONS BY UTILIZING GET_POLY\n",
    "def get_multi(multi):\n",
    "    #replace '), (' which separate polygons to ')&(' to be able to split properly\n",
    "    fxn = multi.replace(\"), (\", \"&\")\n",
    "    #should look like : '(lon lat, ...)&(lon lat,...)&(lon lat,...)'\n",
    "    #split polygons at the ampersand,  leaving strings ready to feed into get_poly\n",
    "    fxn = fxn.split(\"&\") \n",
    "    #should look like : ['(lon lat,...)', '(lon lat,...)', .....] \n",
    "    #create an empty 2D array to store a list of points per polygon, while still keeping together\n",
    "    multi_2d = []\n",
    "    #feed each polygon(i.e. each element in current fxn list) into the get_poly fxn so that each \n",
    "    #polygon has it's own formatted list of points while keeping them all together\n",
    "    for i in range(len(fxn)):\n",
    "        multi_2d.append(get_poly(fxn[i])) \n",
    "        multi_list = np.asarray(multi_2d)\n",
    "    return multi_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#SCRATCH CODE THAT HAS BEEN REMOVED        \n",
    "\n",
    "#     vertex = data.split(\" \")[1:]\n",
    "#     print vertex[1::2]\n",
    "#     first = vertex[0].split(\"(\")[3]\n",
    "#     last = vertex[-1].split(\")\")[0]\n",
    "#     body = vertex[1:-1].split(\",\")\n",
    "#     vertex = [first] + vertex[1:-1] + [last]\n",
    "#     print vertex\n",
    "#     print map(float, vertex)\n",
    "#     y = map(float, vertex)\n",
    "#     y = zip(*[iter(y)]*2)\n",
    "    \n",
    "#     print y\n",
    "\n",
    "#print get_coord(vertex)\n",
    "# final = vertex.apply(get_coord)\n",
    "# print get_coord(vertex[16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#SCALE FUNCTION\n",
    "def scale(num):\n",
    "    #create 14 digits by padding 0's if needed\n",
    "    num1 = str(abs(num[0]))\n",
    "    num2 = str(abs(num[1]))\n",
    "    \n",
    "    if len(num1) < 15:\n",
    "        num1 = num1.ljust(15, '0')\n",
    "    elif len(num1) > 15:\n",
    "        num1 = num1[:15]\n",
    "    \n",
    "    if len(num2) < 15:\n",
    "        num2 = num2.ljust(15, '0')\n",
    "    elif len(num2) > 15:\n",
    "        num2 = num2[:15]\n",
    "    \n",
    "    #shift decimal for 8 decimal places\n",
    "    return np.array([-1.*(float(num1) * (10**5)),-1.*(float(num2) * (10**5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#CENTER FUNCTION\n",
    "def center(coord):\n",
    "    # coord is an np array containing lat and long\n",
    "    \n",
    "    #find mean\n",
    "    mean = coord.mean()\n",
    "    \n",
    "    #center by subtracting the mean\n",
    "    coord = coord - mean\n",
    "    return coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#GENERATE THE GRID LINES\n",
    "\n",
    "\n",
    "#FINDING RANDOM POINTS\n",
    "def find_randpoints(ranges1, ranges2):\n",
    "    #ranges is an array of either lat or long\n",
    "    point1 = np.random.uniform(ranges1[0], ranges1[1], 4)\n",
    "    point2 = np.random.uniform(ranges2[0], ranges2[1], 4)\n",
    "    return point1, point2\n",
    "\n",
    "#6th - Determine where the random points lie in which boundaries (using package)\n",
    "\n",
    "#7th - Set a percentage and determine point location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Testing\n",
    "# (long upper, long lower)\n",
    "coord1 = np.array([-71.13748, -71.14003])\n",
    "#(lat upper, lat lower)\n",
    "coord2 = np.array([42.35827, 42.3601])\n",
    "\n",
    "lon_scaled = scale(coord1)\n",
    "lon_centered = center(lon_scaled)\n",
    "\n",
    "lat_scaled = scale(coord2)\n",
    "lat_centered = center(lat_scaled)\n",
    "\n",
    "# print find_randpoints(lon_centered, lat_centered)\n",
    "# print lon_centered[0],lon_centered[1]\n",
    "# print lat_centered[0], lat_centered[0]\n",
    "\n",
    "# print find_randpoints(coord1, coord2)\n",
    "rand_pt1, rand_pt2 = find_randpoints(coord1, coord2)\n",
    "# print scale(rand_pt1)\n",
    "scaled1 = scale(rand_pt1)\n",
    "# print center(scaled1)\n",
    "\n",
    "# print rand_pt2\n",
    "# print scale(rand_pt2)\n",
    "scaled2 = scale(rand_pt2)\n",
    "# print center(scaled2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def parse_shapes(one_row):\n",
    "    prepped = prep_row(one_row)\n",
    "    is_multi = find_multi(prepped)\n",
    "    if is_multi == True:\n",
    "        prepd_split = get_multi(prepped)\n",
    "        return (prepd_split)\n",
    "    else:\n",
    "        prepd_cleand = get_poly(prepped)\n",
    "        return (prepd_cleand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "poly_test = (parse_shapes(shape_col[10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#APPLY PARSE_SHAPES METHOD TO ALL ELEMENTS OF SHAPE_COL LIST\n",
    "shape_data_pretty = shape_col.apply(parse_shapes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lat_rand = np.array([-71.13794487, -71.13926144, -71.13893327, -71.13919666])\n",
    "lon_rand = np.array([42.35945246, 42.35927083, 42.35915658, 42.35879337])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "ran_point0 = Point(lat_rand[0], lon_rand[0])\n",
    "ran_point1 = Point(lat_rand[1], lon_rand[1])\n",
    "ran_point2 = Point(lat_rand[2], lon_rand[2])\n",
    "ran_point3 = Point(lat_rand[3], lon_rand[3])\n",
    "polygon = Polygon(shape_data_pretty[10])\n",
    "print(polygon.contains(ran_point3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#now we want to write a loop to test point inside each of the gon, then when it's true \n",
    "#need to go back to csv file and check the type of land use attribute \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def is_multi(row):\n",
    "    yes_multi = True\n",
    "    if len(row.shape) > 1:\n",
    "        yes_multi = False\n",
    "    return yes_multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FUNCTION TO TEST POLYGONS\n",
    "def test_point (point, cleaned_data):\n",
    "    test_pt = Point(point[0], point[1]) \n",
    "    positive_gons = []\n",
    "    for i in range(len(cleaned_data)):\n",
    "        test_multi = is_multi(cleaned_data[i])\n",
    "        if test_multi:\n",
    "            for j in range(len(cleaned_data[i])):\n",
    "                polygon1 = Polygon(cleaned_data[i][j])\n",
    "                in_poly = polygon1.contains(test_pt)\n",
    "                if in_poly == True:\n",
    "                    positive_gons.append(i)\n",
    "        else:\n",
    "            in_poly = False\n",
    "            polygon1 = Polygon(cleaned_data[i])\n",
    "            in_poly = polygon1.contains(test_pt)\n",
    "            if in_poly == True:\n",
    "                positive_gons.append(i)\n",
    "    return positive_gons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[14]\n"
     ]
    }
   ],
   "source": [
    "print (test_point([-71.13919666, 42.35879337], shape_data_pretty))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "#FINAL FUNCTION FOR TESTING POINTS\n",
    "def which_polygons(zipped_pts, nice_data):\n",
    "    where_pts_r = []\n",
    "    for i in range(len(zipped_pts)):\n",
    "        where_pts_r.append(test_point(zipped_pts[i], nice_data))\n",
    "    return where_pts_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-71.13794487, 42.35945246]\n"
     ]
    }
   ],
   "source": [
    "some_points = [[-71.13794487, 42.35945246],\n",
    "               [-71.13926144, 42.35927083],\n",
    "               [-71.13893327, 42.35915658],\n",
    "               [-71.13919666, 42.35879337]]\n",
    "print (some_points[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_usage(found_polygons):\n",
    "    usage = []\n",
    "    for i in range(len(found_polygons)):\n",
    "        usage.append(usage_col[found_polygons[i][0]])\n",
    "    return usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Industrial', 'Industrial', 'Industrial', 'Commercial']\n"
     ]
    }
   ],
   "source": [
    "got_em = which_polygons(some_points, shape_data_pretty)\n",
    "print (find_usage(got_em))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
