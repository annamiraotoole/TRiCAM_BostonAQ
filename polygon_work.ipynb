{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from shapely.geometry import Point\n",
    "from shapely.geometry.polygon import Polygon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''find_multi function takes a raw column of data that represents string versions of polygons and multigons and checks \n",
    "to see if it is a polygon or multigon row. This function returns a boolean value that is then used in the function \n",
    "parse_shapes'''\n",
    "#create multigon finder and deal with it separately\n",
    "def find_multi(row):\n",
    "    found = False\n",
    "    if '), (' in row:\n",
    "        found = True\n",
    "    return found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''prep_row function takes a raw row of multi or polygon data and strips off the strings at the beginning and end until\n",
    "the first and last characters are part of the float vertices that will be utilized later. This function is used\n",
    "inside the function parse_shapes.'''\n",
    "#PREP FUNCTION COMES BEFORE FEEDING INTO THE APPROPRIATE MULTI/POLY FUNCTION TO MAKE DATA UNIFORM FORMAT\n",
    "def prep_row(row):\n",
    "    cleaned = row[16:-3]\n",
    "    return cleaned "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''get_poly function takes in a string row of data that represents a single polygon that has been output from either \n",
    "the prep_row function (if the original row was a single polygon) or from the get_multi function. It splits sting\n",
    "on the comma, strips white space, and then converts string values into vertices in formatted cloat format. This \n",
    "is used in the parse_shapes function.'''\n",
    "#GET_POLY FUNCTION CLEANS AND DEALS WITH SINGLE POLYGONS\n",
    "#MULTIPOLYGON ROWS GET FED INTO GET_MULTI, WHICH THEN UTILIZES THIS get_poly FUNCTION WITHIN IT\n",
    "def get_poly(data):\n",
    "    # split the string into elements of a list by each comma\n",
    "    vertex = data.split(\",\")\n",
    "    # strip white spaces from each element\n",
    "    vertex = [item.strip() for item in vertex ]\n",
    "    # format the elements from 'latitude longitude' string to (latitude, longitude) floats\n",
    "    vertex = [(float(item.split(\" \")[0]) ,float(item.split(\" \")[1])) for item in vertex]\n",
    "    return (np.asarray(vertex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''get_multi function takes a prepped string row that represents a multigon, it then cleans the row into a list of \n",
    "string polygons so that each piece of the list can be individually fed into the get_poly function. Each piece that is\n",
    "fed into the get_poly function is cleaned and input into an array. The output is a 2D array of polygons in the same \n",
    "format that all single polygons are in. This is used in the parse_shapes function.'''\n",
    "#GET_MULTI DEALS WITH MULTIPOLYGONS BY UTILIZING GET_POLY\n",
    "def get_multi(multi):\n",
    "    #replace '), (' which separate polygons to ')&(' to be able to split properly\n",
    "    fxn = multi.replace(\"), (\", \"&\")\n",
    "    #should look like : '(lon lat, ...)&(lon lat,...)&(lon lat,...)'\n",
    "    #split polygons at the ampersand,  leaving strings ready to feed into get_poly\n",
    "    fxn = fxn.split(\"&\") \n",
    "    #should look like : ['(lon lat,...)', '(lon lat,...)', .....] \n",
    "    #create an empty 2D array to store a list of points per polygon, while still keeping together\n",
    "    multi_2d = []\n",
    "    #feed each polygon(i.e. each element in current fxn list) into the get_poly fxn so that each \n",
    "    #polygon has it's own formatted list of points while keeping them all together\n",
    "    for i in range(len(fxn)):\n",
    "        multi_2d.append(get_poly(fxn[i])) \n",
    "        multi_list = np.asarray(multi_2d)\n",
    "    return multi_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''scale function scales the data by padding with zeroes and moving the decimal place'''\n",
    "#SCALE FUNCTION\n",
    "def scale(num):\n",
    "    #create 14 digits by padding 0's if needed\n",
    "    num1 = str(abs(num[0]))\n",
    "    num2 = str(abs(num[1]))\n",
    "    \n",
    "    if len(num1) < 15:\n",
    "        num1 = num1.ljust(15, '0')\n",
    "    elif len(num1) > 15:\n",
    "        num1 = num1[:15]\n",
    "    \n",
    "    if len(num2) < 15:\n",
    "        num2 = num2.ljust(15, '0')\n",
    "    elif len(num2) > 15:\n",
    "        num2 = num2[:15]\n",
    "    \n",
    "    #shift decimal for 8 decimal places\n",
    "    return np.array([-1.*(float(num1) * (10**5)),-1.*(float(num2) * (10**5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''center function centers coordinates by subtracting off the mean latitude from all latitude points and the mean \n",
    "longitude from all longitude points'''\n",
    "#CENTER FUNCTION\n",
    "def center(coord):\n",
    "    # coord is an np array containing lat and long\n",
    "    \n",
    "    #find mean\n",
    "    mean = coord.mean()\n",
    "    \n",
    "    #center by subtracting the mean\n",
    "    coord = coord - mean\n",
    "    return coord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''parse_shapes function takes in raw data rows, checks if the rows are multigons or polygons, and then feeds the row into\n",
    "the appropriate function. It returns a cleaned array of vertices for both polygons and multigons. This is used in \n",
    "the test_point function.'''\n",
    "def parse_shapes(one_row):\n",
    "    prepped = prep_row(one_row)\n",
    "    is_multi = find_multi(prepped)\n",
    "    if is_multi == True:\n",
    "        prepd_split = get_multi(prepped)\n",
    "        return (prepd_split)\n",
    "    else:\n",
    "        prepd_cleand = get_poly(prepped)\n",
    "        return (prepd_cleand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''is_multi function tests if the cleaned array of data is a multigon or polygon by looking at the dimensions of the array.\n",
    "This function is used in the test_point function.'''\n",
    "def is_multi(row):\n",
    "    yes_multi = True\n",
    "    if len(row.shape) > 1:\n",
    "        yes_multi = False\n",
    "    return yes_multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''test_point function takes a point and a column of cleaned data and tests the if the point is inside each of the poly \n",
    "or multigons in the column. It returns a list of all poly/multigons which the point is located inside. This function \n",
    "utilizes shapely functions. Used in the which_polygons function.'''\n",
    "#FUNCTION TO TEST POLYGONS\n",
    "def test_point (point, cleaned_data):\n",
    "    test_pt = Point(point[0], point[1]) \n",
    "    positive_gons = []\n",
    "    for i in range(len(cleaned_data)):\n",
    "        test_multi = is_multi(cleaned_data[i])\n",
    "        if test_multi:\n",
    "            for j in range(len(cleaned_data[i])):\n",
    "                polygon1 = Polygon(cleaned_data[i][j])\n",
    "                in_poly = polygon1.contains(test_pt)\n",
    "                if in_poly == True:\n",
    "                    positive_gons.append(i)\n",
    "        else:\n",
    "            in_poly = False\n",
    "            polygon1 = Polygon(cleaned_data[i])\n",
    "            in_poly = polygon1.contains(test_pt)\n",
    "            if in_poly == True:\n",
    "                positive_gons.append(i)\n",
    "    return positive_gons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''which_polygons function generalizes the testing process by taking in an array of points and a column of cleaned data and \n",
    "testing each point against each poly/multigon in the column of cleaned data. Outputs an array of lists where each list \n",
    "corresponds to the polygons for which a given point falls into. This function is used in the wrapper function.'''\n",
    "def which_polygons(zipped_pts, nice_data):\n",
    "    where_pts_r = []\n",
    "    for i in range(len(zipped_pts)):\n",
    "        where_pts_r.append(test_point(zipped_pts[i], nice_data))\n",
    "    return where_pts_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''find_usage function takes in an array of found polygons and a column of string values that represent land usage. The \n",
    "function uses the integer that corresponds to a polygon, and cross checks to the land usage column to find the \n",
    "land usage that each point falls into. This outputs a list of Strings that tells user what type of land each point is \n",
    "located in. This function is used in wrapper class.'''\n",
    "def find_usage(found_polygons, usage_column):\n",
    "    usage = []\n",
    "    usage_col = usage_column\n",
    "    for i in range(len(found_polygons)):\n",
    "        usage.append(usage_col[found_polygons[i][0]])\n",
    "    return usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''wrapper function utilizes all functions above by taking in an array of zipped points to be checked, a column of \n",
    "uncleaned polygon data, and a column that will be cross checked. It outputs the land usage of each of the points \n",
    "passed in as a parameter.'''\n",
    "def wrapper(zipped_points, uncleaned_data_col, cross_checked_col):\n",
    "    points = zipped_points\n",
    "    raw_data = uncleaned_data_col\n",
    "    cleaned_data = raw_data.apply(parse_shapes)\n",
    "    locations_of_points = which_polygons(points, cleaned_data)\n",
    "    land_use = find_usage(locations_of_points, cross_checked_col)\n",
    "    return land_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-71.13794487, 42.35945246]\n"
     ]
    }
   ],
   "source": [
    "some_points = [[-71.13794487, 42.35945246],\n",
    "               [-71.13926144, 42.35927083],\n",
    "               [-71.13893327, 42.35915658],\n",
    "               [-71.13919666, 42.35879337]]\n",
    "print (some_points[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "#read in a csv file\n",
    "data = pd.read_csv(\"small_scale_data.csv\")\n",
    "#pull out only the shape column which are all in string format\n",
    "shape_col = data[\"SHAPE\"]\n",
    "#pull out column of attributes you are also using \n",
    "usage_data = data[\"LU05_DESC\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Industrial', 'Industrial', 'Industrial', 'Commercial']\n"
     ]
    }
   ],
   "source": [
    "#TESTING WRAPPER CLASS\n",
    "print (wrapper(some_points, shape_col, usage_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
