{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from shapely.geometry import Point\n",
    "from shapely.geometry.polygon import Polygon\n",
    "from collections import Counter\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#read in a csv file\n",
    "data_land = pd.read_csv(\"land_use_medium.csv\")\n",
    "data_open = pd.read_csv(\"open_space_medium.csv\")\n",
    "#pull out only the shape column which are all in string format\n",
    "shape_open = data_open[\"SHAPE\"]\n",
    "shape_col = data_land[\"SHAPE\"]\n",
    "#pull out column of attributes you are also using \n",
    "usage_data = data_land[\"LU05_DESC\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generate_grid(x, y, cell_num):\n",
    "    \"\"\" Inputs: array with latitude min and latitude max, array with longitude min and longitude max, and number of cells\n",
    "    Actions: Creates a grid using this data\n",
    "    Outputs: an array of the x ticks, an array of the y ticks, the x and y widths of a single cell \"\"\"\n",
    "\n",
    "    x_min = x[0]\n",
    "    x_max = x[1]\n",
    "\n",
    "\n",
    "\n",
    "    y_min = y[0]\n",
    "    y_max = y[1]\n",
    "\n",
    "    #Create ticks\n",
    "    x_s = np.linspace(x_min, x_max, cell_num + 1)\n",
    "    y_s = np.linspace(y_min, y_max, cell_num + 1)\n",
    "\n",
    "    #Create grid\n",
    "    x_coord, y_coord = np.meshgrid(x_s, y_s)\n",
    "\n",
    "    #length and width of a single cell\n",
    "    x_shift = np.abs(x_s[1] - x_s[0])\n",
    "    y_shift = np.abs(y_s[1] - y_s[0])\n",
    "    return x_coord, y_coord, x_shift, y_shift"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gen_rand_pts(min_lat, min_long, delta_x, delta_y, y_cell, x_cell, rand_num):\n",
    "    \"\"\" Inputs: latitude min, latitude max, longitude min, longitude max, number of x and y cells, number of random points\n",
    "    Actions: First, it creates random points within the boundaries of a single cell. Then, it translates these random points\n",
    "    to each cell.\n",
    "    Outputs: a list of arrays of random points per cell \"\"\"\n",
    "    #generate random points of a single cell\n",
    "    rand_x_grid1 = np.random.uniform(min_lat, min_lat + x_shift, rand_num)\n",
    "    rand_y_grid1 = np.random.uniform(min_long, min_long + y_shift, rand_num)\n",
    "    old_grid_pts = np.array(list(zip(rand_x_grid1, rand_y_grid1)))\n",
    "    plt.scatter(rand_x_grid1, rand_y_grid1)\n",
    "    plt.show()\n",
    "    \n",
    "    list_of_pts = []  \n",
    "    new_grid_pts = np.copy(old_grid_pts)\n",
    "    for y_tick in range(y_cell):\n",
    "        for x_tick in range(x_cell):\n",
    "            new_grid_pts[:, 0] =  old_grid_pts[:, 0] + delta_x * x_tick #shift horizontally\n",
    "            list_of_pts.append(np.copy(new_grid_pts))\n",
    "        new_grid_pts[:, 1] += delta_y #shift vertically\n",
    "    return list_of_pts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYoAAAD8CAYAAABpcuN4AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x115029e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\"\"\"Testing the function above\"\"\"\n",
    "x = [ -71.20197, -70.96679]\n",
    "y = [42.291441, 42.420578]\n",
    "cell_num = 130\n",
    "x_cell = 130\n",
    "y_cell = 130\n",
    "num_pts = 100\n",
    "x_coord, y_coord, x_shift, y_shift = generate_grid(x, y, cell_num)\n",
    "\n",
    "rand_pts = gen_rand_pts(x[0], y[0], x_shift, y_shift, x_cell, y_cell, num_pts)\n",
    "list_rand = [np.array_str(array) for array in rand_pts]\n",
    "data_export = pd.DataFrame(list_rand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "correct_rand_pts = open('correct_randoms', 'wb')\n",
    "pickle.dump(rand_pts, correct_rand_pts)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-71.20141289  42.29150493]\n",
      " [-71.20101778  42.29221551]\n",
      " [-71.20185416  42.29192886]\n",
      " [-71.20110769  42.29148812]\n",
      " [-71.20038221  42.29228739]\n",
      " [-71.20020091  42.2919532 ]\n",
      " [-71.20167462  42.29154053]\n",
      " [-71.2011223   42.29193904]\n",
      " [-71.20170029  42.29182739]\n",
      " [-71.20158805  42.29159617]\n",
      " [-71.20167967  42.29181034]\n",
      " [-71.20069453  42.29210085]\n",
      " [-71.20152135  42.29196248]\n",
      " [-71.20059561  42.29156998]\n",
      " [-71.2010158   42.291445  ]\n",
      " [-71.20052454  42.29231945]\n",
      " [-71.20133793  42.29193898]\n",
      " [-71.20128971  42.29221548]\n",
      " [-71.20145061  42.29152411]\n",
      " [-71.20058983  42.29174274]\n",
      " [-71.20144656  42.29157922]\n",
      " [-71.2014889   42.29161972]\n",
      " [-71.20109395  42.29190794]\n",
      " [-71.20022603  42.29153767]\n",
      " [-71.20115679  42.29218626]\n",
      " [-71.20098603  42.29231557]\n",
      " [-71.20071825  42.29188253]\n",
      " [-71.20193067  42.29165373]\n",
      " [-71.20068945  42.29214166]\n",
      " [-71.20081     42.29146882]\n",
      " [-71.20035568  42.29212169]\n",
      " [-71.2016484   42.29231777]\n",
      " [-71.20173077  42.29174381]\n",
      " [-71.20128637  42.29179782]\n",
      " [-71.20103274  42.29227615]\n",
      " [-71.20153998  42.29212092]\n",
      " [-71.20103592  42.2921958 ]\n",
      " [-71.2007346   42.29158984]\n",
      " [-71.20110229  42.29237572]\n",
      " [-71.20194844  42.2914877 ]\n",
      " [-71.20016349  42.29156695]\n",
      " [-71.20154656  42.29147903]\n",
      " [-71.2011173   42.29161441]\n",
      " [-71.20144958  42.29204356]\n",
      " [-71.20043696  42.2917993 ]\n",
      " [-71.20032211  42.29187824]\n",
      " [-71.20017827  42.29209336]\n",
      " [-71.20044048  42.29227898]\n",
      " [-71.20113594  42.2918094 ]\n",
      " [-71.20079114  42.29218685]\n",
      " [-71.20113434  42.29224693]\n",
      " [-71.2007425   42.29225748]\n",
      " [-71.2019332   42.29185658]\n",
      " [-71.20127753  42.29198145]\n",
      " [-71.20171697  42.29189896]\n",
      " [-71.20032106  42.29200142]\n",
      " [-71.2008466   42.29171374]\n",
      " [-71.20095136  42.29151695]\n",
      " [-71.20144825  42.29170508]\n",
      " [-71.2014409   42.29151492]\n",
      " [-71.2009679   42.29188764]\n",
      " [-71.20193675  42.292342  ]\n",
      " [-71.2007396   42.29146647]\n",
      " [-71.2012943   42.2915424 ]\n",
      " [-71.2011402   42.29173105]\n",
      " [-71.20108798  42.29204802]\n",
      " [-71.20072878  42.29192501]\n",
      " [-71.20064324  42.29171189]\n",
      " [-71.20160069  42.29196946]\n",
      " [-71.20083123  42.29178112]\n",
      " [-71.2006313   42.29204015]\n",
      " [-71.20127022  42.29186735]\n",
      " [-71.20048072  42.29221927]\n",
      " [-71.20173038  42.2924111 ]\n",
      " [-71.20131833  42.29232346]\n",
      " [-71.20056313  42.2916971 ]\n",
      " [-71.2018208   42.29167825]\n",
      " [-71.20154914  42.29240621]\n",
      " [-71.20018943  42.29154854]\n",
      " [-71.20113637  42.29169349]\n",
      " [-71.20109219  42.29215892]\n",
      " [-71.20043008  42.29158484]\n",
      " [-71.20172485  42.29176822]\n",
      " [-71.20177376  42.29195742]\n",
      " [-71.20022167  42.29215983]\n",
      " [-71.20101976  42.29183521]\n",
      " [-71.20102006  42.29220304]\n",
      " [-71.20180594  42.29219539]\n",
      " [-71.20114647  42.29191599]\n",
      " [-71.20082938  42.291897  ]\n",
      " [-71.2010047   42.29226058]\n",
      " [-71.20043219  42.29227952]\n",
      " [-71.20129716  42.29204971]\n",
      " [-71.20185436  42.29191386]\n",
      " [-71.20192972  42.291961  ]\n",
      " [-71.20154059  42.29145477]\n",
      " [-71.20138636  42.29171107]\n",
      " [-71.20057532  42.29177892]\n",
      " [-71.20052276  42.29181895]\n",
      " [-71.20072708  42.29197766]]\n"
     ]
    }
   ],
   "source": [
    "file = pickle.load(open('correct_randoms', 'rb'))\n",
    "print (file[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 131\n",
    "m = 131\n",
    "\n",
    "empty_array = np.zeros((n,m)).astype(str)\n",
    "for x in range(n):\n",
    "    for y in range(m):\n",
    "        empty_array[x][y] = np.array_str(np.array((x_coord[x][y], y_coord[x][y])))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "array_grid_pd = pd.DataFrame(empty_array)\n",
    "array_grid_pd.to_csv(\"grid_points.csv\")\n",
    "# print (grid_array.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''find_multi function takes a raw column of data that represents string versions of polygons and multigons and checks \n",
    "to see if it is a polygon or multigon row. This function returns a boolean value that is then used in the function \n",
    "parse_shapes'''\n",
    "#create multigon finder and deal with it separately\n",
    "def find_multi(row):\n",
    "    found = False\n",
    "    if '), (' in row:\n",
    "        found = True\n",
    "    return found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''prep_row function takes a raw row of multi or polygon data and strips off the strings at the beginning and end until\n",
    "the first and last characters are part of the float vertices that will be utilized later. This function is used\n",
    "inside the function parse_shapes.'''\n",
    "#PREP FUNCTION COMES BEFORE FEEDING INTO THE APPROPRIATE MULTI/POLY FUNCTION TO MAKE DATA UNIFORM FORMAT\n",
    "def prep_row(row):\n",
    "    cleaned = row[16:-3]\n",
    "    return cleaned "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''get_poly function takes in a string row of data that represents a single polygon that has been output from either \n",
    "the prep_row function (if the original row was a single polygon) or from the get_multi function. It splits sting\n",
    "on the comma, strips white space, and then converts string values into vertices in formatted cloat format. This \n",
    "is used in the parse_shapes function.'''\n",
    "#GET_POLY FUNCTION CLEANS AND DEALS WITH SINGLE POLYGONS\n",
    "#MULTIPOLYGON ROWS GET FED INTO GET_MULTI, WHICH THEN UTILIZES THIS get_poly FUNCTION WITHIN IT\n",
    "def get_poly(data):\n",
    "    # split the string into elements of a list by each comma\n",
    "    vertex = data.split(\",\")\n",
    "    # strip white spaces from each element\n",
    "    vertex = [item.strip() for item in vertex ]\n",
    "    # format the elements from 'latitude longitude' string to (latitude, longitude) floats\n",
    "    vertex = [(float(item.split(\" \")[0]) ,float(item.split(\" \")[1])) for item in vertex]\n",
    "    return (np.asarray(vertex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''get_multi function takes a prepped string row that represents a multigon, it then cleans the row into a list of \n",
    "string polygons so that each piece of the list can be individually fed into the get_poly function. Each piece that is\n",
    "fed into the get_poly function is cleaned and input into an array. The output is a 2D array of polygons in the same \n",
    "format that all single polygons are in. This is used in the parse_shapes function.'''\n",
    "#GET_MULTI DEALS WITH MULTIPOLYGONS BY UTILIZING GET_POLY\n",
    "def get_multi(multi):\n",
    "    #replace '), (' which separate polygons to ')&(' to be able to split properly\n",
    "    fxn = multi.replace(')), ((', \"&\")\n",
    "    fxn = fxn.replace(\"), (\", \"&\")\n",
    "    #should look like : '(lon lat, ...)&(lon lat,...)&(lon lat,...)'\n",
    "    #split polygons at the ampersand,  leaving strings ready to feed into get_poly\n",
    "    fxn = fxn.split(\"&\") \n",
    "    #should look like : ['(lon lat,...)', '(lon lat,...)', .....] \n",
    "    #create an empty 2D array to store a list of points per polygon, while still keeping together\n",
    "    multi_2d = []\n",
    "    #feed each polygon(i.e. each element in current fxn list) into the get_poly fxn so that each \n",
    "    #polygon has it's own formatted list of points while keeping them all together\n",
    "    for i in range(len(fxn)):\n",
    "        multi_2d.append(get_poly(fxn[i])) \n",
    "        multi_list = np.asarray(multi_2d)\n",
    "    return multi_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''parse_shapes function takes in raw data rows, checks if the rows are multigons or polygons, and then feeds the row into\n",
    "the appropriate function. It returns a cleaned array of vertices for both polygons and multigons. This is used in \n",
    "the test_point function.'''\n",
    "def parse_shapes(one_row):\n",
    "    prepped = prep_row(one_row)\n",
    "    a_multi = find_multi(prepped)\n",
    "    if a_multi == True:\n",
    "        prepd_split = get_multi(prepped)\n",
    "        return (prepd_split)\n",
    "    else:\n",
    "        prepd_cleand = get_poly(prepped)\n",
    "        return (prepd_cleand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''is_multi function tests if the cleaned array of data is a multigon or polygon by looking at the dimensions of the array.\n",
    "This function is used in the test_point function.'''\n",
    "def is_multi(row):\n",
    "    yes_multi = True\n",
    "    if len(row.shape) > 1:\n",
    "        yes_multi = False\n",
    "    return yes_multi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''test_point function takes a point and a column of cleaned data and tests the if the point is inside each of the poly \n",
    "or multigons in the column. It returns a list of all poly/multigons which the point is located inside. This function \n",
    "utilizes shapely functions. Used in the which_polygons function.'''\n",
    "#FUNCTION TO TEST POLYGONS\n",
    "def test_point (point, cleaned_data):\n",
    "    test_pt = Point(point[0], point[1]) \n",
    "    positive_gons = []\n",
    "    for i in range(len(cleaned_data)):\n",
    "        test_multi = is_multi(cleaned_data[i])\n",
    "        if test_multi:\n",
    "            for j in range(len(cleaned_data[i])): #FOR EVERY POLYGON IN MULTIGON\n",
    "                polygon1 = Polygon(cleaned_data[i][j])\n",
    "                in_poly = polygon1.contains(test_pt)\n",
    "                if in_poly == True:\n",
    "                    positive_gons.append(i)\n",
    "        else:\n",
    "            in_poly = False\n",
    "            polygon1 = Polygon(cleaned_data[i])\n",
    "            in_poly = polygon1.contains(test_pt)\n",
    "            if in_poly == True:\n",
    "                positive_gons.append(i)\n",
    "    return positive_gons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''which_polygons function generalizes the testing process by taking in an array of points and a column of cleaned data and \n",
    "testing each point against each poly/multigon in the column of cleaned data. Outputs an array of lists where each list \n",
    "corresponds to the polygons for which a given point falls into. This function is used in the wrapper function.'''\n",
    "def which_polygons(zipped_pts, nice_data):\n",
    "    where_pts_r = []\n",
    "    for i in range(len(zipped_pts)):\n",
    "        where_pts_r.append(test_point(zipped_pts[i], nice_data))\n",
    "    return where_pts_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''find_usage function takes in an array of found polygons and a column of string values that represent land usage. The \n",
    "function uses the integer that corresponds to a polygon, and cross checks to the land usage column to find the \n",
    "land usage that each point falls into. This outputs a list of Strings that tells user what type of land each point is \n",
    "located in. This function is used in wrapper class.'''\n",
    "def find_usage(found_polygons, usage_column):\n",
    "    usage = []\n",
    "    usage_col = usage_column\n",
    "    for i in range(len(found_polygons)):\n",
    "        usage.append(usage_col[found_polygons[i][0]])\n",
    "    return usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_open(found_polygons):\n",
    "    in_open = []\n",
    "    for i in range(len(found_polygons)):\n",
    "        if len(found_polygons[i]) == 0:\n",
    "            in_open.append(False)\n",
    "        else:\n",
    "            in_open.append(True)\n",
    "    return in_open"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''wrapper_landuse function utilizes all functions above by taking in an array of zipped points to be checked, a column of \n",
    "uncleaned polygon data, and a column that will be cross checked. It outputs the land usage of each of the points \n",
    "passed in as a parameter.'''\n",
    "def wrapper_landuse(zipped_points, uncleaned_data_col, cross_checked_col):\n",
    "    points = zipped_points\n",
    "    raw_data = uncleaned_data_col\n",
    "    \n",
    "    start = time.time()\n",
    "    cleaned_data = raw_data.apply(parse_shapes)\n",
    "    end = time.time()\n",
    "    applyfxntime = end - start\n",
    "    print (applyfxntime)\n",
    "    \n",
    "    start = time.time()\n",
    "    locations_of_points = which_polygons(points, cleaned_data)\n",
    "    end = time.time()\n",
    "    wptime = end - start\n",
    "    print (wptime)\n",
    "    \n",
    "    start = time.time()\n",
    "    land_use = find_usage(locations_of_points, cross_checked_col)\n",
    "    end = time.time()\n",
    "    futime = end - start \n",
    "    print (futime)\n",
    "    \n",
    "    return land_use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''wrapper_openspace function utilizes all functions above (other than find_open) by taking in an array of zipped \n",
    "points to be checked and a column of uncleaned polygon data. It outputs a list of booleans saying whether the points\n",
    "are inside open space polygons or not.'''\n",
    "def wrapper_openspace(zipped_points, uncleaned_data_col):\n",
    "    points = zipped_points\n",
    "    raw_data = uncleaned_data_col\n",
    "    cleaned_data = raw_data.apply(parse_shapes)\n",
    "    locations_of_points = which_polygons(points, cleaned_data)\n",
    "    open_space = find_open(locations_of_points)\n",
    "    return open_space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05662417411804199\n",
      "0.25394392013549805\n",
      "0.00010704994201660156\n",
      "['Multi-Family Residential', 'Multi-Family Residential', 'Commercial', 'Multi-Family Residential']\n",
      "Counter({'Multi-Family Residential': 3, 'Commercial': 1})\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "#TESTING LAND USE WRAPPER CLASS\n",
    "usage_list = wrapper_landuse(some_points, shape_col, usage_data)\n",
    "print (usage_list)\n",
    "counted = Counter(usage_list)\n",
    "print (counted)\n",
    "print (counted[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TESTING OPEN SPACE WRAPPER CLASS\n",
    "open_stuff = wrapper_openspace(more_points, shape_open)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def proportion_land(list):\n",
    "    length = len(list)\n",
    "    prop_list = Counter(list)\n",
    "    these_keys = prop_list.keys()\n",
    "    for key in these_keys:\n",
    "        prop_list[key]/=length\n",
    "    return prop_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({False: 1.0})\n"
     ]
    }
   ],
   "source": [
    "print (proportion_land(open_stuff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_open_prop(list_rands, open_column):\n",
    "    dict_of_props = []\n",
    "    for points in range(len(list_rands)):\n",
    "        set_randoms = list_rands[points]\n",
    "        list_of_open = wrapper_openspace(set_randoms, open_column)\n",
    "        proportions = proportion_land(list_of_open)\n",
    "        dict_of_props.append(proportions)\n",
    "    return dict_of_props"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def find_land_prop(list_rands, land_column, usage_column):\n",
    "    dict_of_props = []\n",
    "    for points in range(len(list_rands)):\n",
    "        set_randoms = list_rands[points]\n",
    "        list_of_use = wrapper_landuse(set_randoms, shape_col, usage_data)\n",
    "        proportions = proportion_land(list_of_use)\n",
    "        dict_of_props.append(proportions)\n",
    "    return dict_of_props"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.05832195281982422\n",
      "0.21124625205993652\n",
      "0.00031495094299316406\n",
      "0.049268245697021484\n",
      "0.21188879013061523\n",
      "6.914138793945312e-05\n",
      "0.05185699462890625\n",
      "0.2436840534210205\n",
      "6.008148193359375e-05\n",
      "0.04759025573730469\n",
      "0.21383118629455566\n",
      "6.794929504394531e-05\n",
      "[Counter({'Multi-Family Residential': 1.0}), Counter({'Multi-Family Residential': 0.5, 'Commercial': 0.25, 'Industrial': 0.25}), Counter({'Multi-Family Residential': 1.0}), Counter({'Multi-Family Residential': 0.75, 'Urban Public/Institutional': 0.25})]\n"
     ]
    }
   ],
   "source": [
    "#TESTING \n",
    "print (find_land_prop(rand_pts, shape_open, usage_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
