{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Import packages </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn as sk\n",
    "from sklearn import mixture\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import preprocessing\n",
    "from statsmodels.tools import add_constant\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.gaussian_process.kernels import ConstantKernel as C\n",
    "from sklearn.gaussian_process.kernels import Matern, WhiteKernel, RationalQuadratic, DotProduct\n",
    "import statsmodels.api as sm\n",
    "import random\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set(style=\"ticks\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Saved constants </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "LU = pd.read_csv('boston_site_LU.csv')\n",
    "LU_width = LU.shape[1]\n",
    "col_names = ['Cropland', 'Golf Course',\n",
    "       'Saltwater Sandy Beach', 'cemetary', 'commercial', 'crop_land',\n",
    "       'forest', 'high_density_residential', 'industrial',\n",
    "       'low_density_residential', 'marina', 'medium_density_residential',\n",
    "       'mining', 'open_land', 'recreational', 'transitional', 'transportation',\n",
    "       'urban_public/institutional', 'waste', 'water', 'wetland', 'Sample Collection Start Time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "weather_col_names = ['temp_c', 'relative_humidity', 'wind_kph',\n",
    "                     'pressure_mb','visibility_km', 'UV',\n",
    "                     'precip_today_in']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-66-206b97df1f53>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-66-206b97df1f53>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    lat = AQ['Latitude']\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "AQ = pd.read_csv('Appended_AQ_Data/')\n",
    "    \n",
    "    lat = AQ['Latitude']\n",
    "    lon = AQ['Longitude']\n",
    "    AQ['lat_lon'] = list(zip(lat, lon))\n",
    "    pts = AQ['lat_lon']\n",
    "    \n",
    "LU = pd.read_csv('boston_site_LU.csv')\n",
    "sites = LU['Site']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "W = pd.read_csv('wunderground_csvs/weather_averages.csv')\n",
    "lat = W['latitude']\n",
    "lon = W['longitude']\n",
    "stations = list(zip(lat, lon))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pollutants = ['CO', 'SO', 'NO', 'OZO', 'PM']\n",
    "local_path = 'Appended_AQ_Data/'\n",
    "\n",
    "alphas = [0.000888, 0.000000001, 0.000001, 0.00001, 0.000588]\n",
    "\n",
    "x_label = 'Time'\n",
    "y_labels = pollutants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate grid vertices/ticks\n",
    "\n",
    "x = [ -71.20197, -70.96679]\n",
    "y = [42.291441, 42.420578]\n",
    "x_cell = 50\n",
    "y_cell = 50\n",
    "\n",
    "x_min = -71.20197\n",
    "x_max = -70.96679\n",
    "y_min = 42.291441\n",
    "y_max = 42.420578\n",
    "\n",
    "# create ticks\n",
    "x_s = np.linspace(x_min, x_max, x_cell + 1)\n",
    "y_s = np.linspace(y_min, y_max, y_cell + 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Define functions for land use data cleaning</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# given lat/lon spot\n",
    "# return indicies for lat/lon grid box bounds\n",
    "# where bounds are:\n",
    "# y_s[lat_index - 1], y_s[lat_index]\n",
    "# x_s[lon_index - 1], x_s[lon_index]\n",
    "def find_gridbox(lat, long):\n",
    "    # locate correct grid box bounds\n",
    "    lat_index = 0\n",
    "    lon_index = 0\n",
    "    for i in range(0, 50):\n",
    "        if x_s[i] < long:\n",
    "            lon_index = i\n",
    "        if y_s[i] > lat:\n",
    "            lon_index = i\n",
    "    return (lat_index, lon_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# function to parse string from \"Grids\" column in boston_preds.csv\n",
    "# returns list of grid vertices as float64 tuples\n",
    "def parse_str(str_edit):\n",
    "    str_edit = str_edit.replace('[', '')\n",
    "    str_edit = str_edit.replace('(', '')\n",
    "    str_edit = str_edit.replace(']', '')\n",
    "    str_edit = str_edit.replace(')', '')\n",
    "    str_edit = str_edit.replace(',', '')\n",
    "    list = str_edit.split(' ')\n",
    "    return [(np.float64(list[0]), np.float64(list[1])), (np.float64(list[2]), np.float64(list[3])),\n",
    "            (np.float64(list[4]), np.float64(list[5])), (np.float64(list[6]), np.float64(list[7]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# given lat, lon, and string containing cell verticies as tuples\n",
    "# return boolean value of whether or not lat/lon point is in cell\n",
    "\n",
    "def in_cell(lat, lon, cell):\n",
    "    cell_points = parse_str(cell)\n",
    "    lat_bool = lat > cell_points[0][0] and lat < cell_points[2][0]\n",
    "    lon_bool = lon > cell_points[0][1] and lon < cell_points[2][1]\n",
    "    if lat_bool and lon_bool:\n",
    "        return True\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unexpected indent (<ipython-input-73-b9dc94185946>, line 54)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-73-b9dc94185946>\"\u001b[0;36m, line \u001b[0;32m54\u001b[0m\n\u001b[0;31m    'precip_today_in'\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unexpected indent\n"
     ]
    }
   ],
   "source": [
    "# adds land use columns to passed in dataframe,\n",
    "# returns edited version of dataframe\n",
    "\n",
    "def add_columns(df):\n",
    "    \n",
    "    # add land use columns\n",
    "    df['Cropland'] = 0\n",
    "    df['Golf Course'] = 0\n",
    "    df['Saltwater Sandy Beach'] = 0\n",
    "    df['cemetary'] = 0\n",
    "    df['commercial'] = 0\n",
    "    df['crop_land'] = 0\n",
    "    df['forest'] = 0\n",
    "    df['high_density_residential'] = 0\n",
    "    df['industrial'] = 0\n",
    "    df['low_density_residential'] = 0\n",
    "    df['marina'] = 0\n",
    "    df['medium_density_residential'] = 0\n",
    "    df['mining'] = 0\n",
    "    df['open_land'] = 0\n",
    "    df['recreational'] = 0\n",
    "    df['transitional'] = 0\n",
    "    df['transportation'] = 0\n",
    "    df['urban_public/institutional'] = 0\n",
    "    df['waste'] = 0\n",
    "    df['water'] = 0\n",
    "    df['wetland'] = 0\n",
    "    \n",
    "    # add weather columns\n",
    "    df['temp_c'] = 0\n",
    "    df['relative_humidity'] = 0\n",
    "    df['wind_kph'] = 0\n",
    "    df['pressure_mb'] = 0\n",
    "    df['visibility_km'] = 0\n",
    "    df['UV'] = 0\n",
    "    df['precip_today_in'] = 0\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# AQ_df is the Boston AQ hourly\n",
    "# LU_df contains the cells and the landuse\n",
    "# AQ_index is the row of the cell that contains the point in the Boston AQ hourly df\n",
    "# LU_index is the row of the cell that contains the point in the cell and landuse df\n",
    "\n",
    "def update_proportions(AQ_df, LU_df, AQ_index, LU_index):\n",
    "    \n",
    "    for col in range(0, LU_width - 2):#df.loc[i, 'forest'] = df.loc[i, 'forest'] + my_dict['forest']\n",
    "        # print (AQ_index, AQ_width + col, LU_index, col + 1), \"\\n\"\n",
    "        # print AQ_df.iloc[AQ_index, col + AQ_width], \"LU:\", LU_df.iloc[LU_index, col+2]\n",
    "        AQ_df.iloc[AQ_index, col + AQ_width] = LU_df.iloc[LU_index, col + 2]\n",
    "    \n",
    "    return AQ_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#AQ_df is the Boston AQ hourly\n",
    "#LU_df contains the cells and the landuse\n",
    "#AQ_index is the row of the cell that contains the point in the Boston AQ hourly df\n",
    "#LU_index is the row of the cell that contains the point in the cell and landuse df\n",
    "\n",
    "def fill_in_weather(aq_df, weather_df, aq_index, weather_index):\n",
    "    \n",
    "    aq_df.iloc[aq_index, \"Weather\"] = weather_df.iloc[weather_index, \"weather\"]\n",
    "    \n",
    "    return aq_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# return numerical distance between two lat lon points\n",
    "def get_distance(aq_lat, aq_lon, weather_lat, weather_lon):\n",
    "    dist = math.sqrt((aq_lat - weather_lat)**2 + (aq_lon - weather_lon)**2)\n",
    "    return dist\n",
    "\n",
    "# given lat lon point, return index of row in weather_averages.csv file\n",
    "# that represents the closest sensor\n",
    "def find_sensor(aq_lat, aq_lon):\n",
    "    distances = []\n",
    "    for index in range(len(stations)):\n",
    "        distances[index] = get_distance(aq_lat, aq_lon, stations[i][0], stations[i][1])\n",
    "    return distances.index(min(distances))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Define functions needed for Gaussian process </h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"Cleans the times to a parsable format for multiple days in a row\"\"\"\n",
    "def clean_time_multiple(DF, col_name):\n",
    "    \n",
    "    times = []\n",
    "    time = list(DF[col_name])\n",
    "    \n",
    "    prev_T = float(time[0][:2])\n",
    "    day = 0\n",
    "    \n",
    "    for i in range(len(time)):\n",
    "        T = float(time[i][:2])\n",
    "        if prev_T > T:\n",
    "            day += 1\n",
    "        times.append(T + day*24)\n",
    "        prev_T = T\n",
    "    \n",
    "    DF[col_name] = times\n",
    "    \n",
    "    return DF\n",
    "\n",
    "\"\"\"Splits dataframe into train and test data\"\"\"\n",
    "def split_train_test(df):\n",
    "    train, test = train_test_split(df, test_size=.30, random_state=0)\n",
    "    x_train = train[\"Sample Collection Start Time\"]\n",
    "    y_train = train[\"Measure Value\"]\n",
    "    x_test = test[\"Sample Collection Start Time\"]\n",
    "    y_test = test[\"Measure Value\"]\n",
    "    return x_train, y_train, x_test, y_test\n",
    "\n",
    "\"\"\"\n",
    "Creates Gaussian model, computs r squarred, MSE and log liklihood\n",
    "Given x_train, y_train, x_test, and y_test data, and numerical alpha value\n",
    "Prints train and test R^2\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def simple_gaussian(x_train, y_train, x_test, y_test, alpha):\n",
    "    \n",
    "    train_size = x_train.shape[0]\n",
    "    test_size = x_test.shape[0]\n",
    "    \n",
    "    kern = RBF(length_scale = 1)\n",
    "    \n",
    "    gp = GaussianProcessRegressor(kernel=kern, alpha=alpha, optimizer='fmin_l_bfgs_b', n_restarts_optimizer=1, normalize_y=False, copy_X_train=False, random_state=None)\n",
    "    gp.fit(x_train.reshape(train_size, 1), y_train.reshape(train_size, 1))\n",
    "\n",
    "    y_train_pred, sigma_train = gp.predict(x_train.reshape(train_size, 1), return_std=True)\n",
    "    y_test_pred, sigma_test = gp.predict(x_test.reshape(test_size, 1), return_std=True)\n",
    "\n",
    "    # get R^2\n",
    "    r2 = gp.score(x_train.reshape(train_size, 1), y_train.reshape(train_size, 1))\n",
    "    r2_t = gp.score(x_test.reshape(test_size, 1), y_test.reshape(test_size, 1))\n",
    "\n",
    "    # get MSE measurements\n",
    "    MSE_test = np.mean((y_test_pred - y_test.reshape(test_size, 1))**2)\n",
    "    MSE_train = np.mean((y_train_pred - y_train.reshape(train_size, 1))**2)\n",
    "\n",
    "    # get log likelihood\n",
    "    t = gp.log_marginal_likelihood()\n",
    "\n",
    "    # calculate AIC\n",
    "    AIC = 2*len(x_test) - 2*np.log(-t)\n",
    "    \n",
    "    # print R^2 values\n",
    "    print('mean squared error of train data with model = ' + str(MSE_train))\n",
    "    print('mean squared error of test data with model = ' + str(MSE_test))\n",
    "    print('Akaike information criterion = ' + str(AIC))\n",
    "    print('log likelihood of model = ' + str(t))\n",
    "    print('training R^2 value = ' + str(r2))\n",
    "    print('testing R^2 value = ' + str(r2_t))\n",
    "    \n",
    "    return y_train_pred, y_test_pred, gp\n",
    "\n",
    "\"\"\"Plots predicted y values for testing set\"\"\"\n",
    "def plot_predictions(x_test, y_test, y_test_pred, x_label, y_label):\n",
    "    plt.figure(figsize=(13,8))\n",
    "    plt.plot(x_test, y_test, '.', color=\"b\",)\n",
    "    plt.scatter(x_test, y_test_pred, color='r')\n",
    "    plt.xlabel(x_label)\n",
    "    plt.title(y_label)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Code to combine AQ data file with land use data and implement Gaussian process</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'math' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-61-aa80bfff943e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m                 \u001b[0;31m# add cell info to appendedAQ.csv file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m                 \u001b[0mAQ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mupdate_proportions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m         \u001b[0mweather_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfind_sensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m         \u001b[0mAQ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfill_in_weather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAQ\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLU\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweather_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-59-f34700b61b9c>\u001b[0m in \u001b[0;36mfind_sensor\u001b[0;34m(aq_lat, aq_lon)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mdistances\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstations\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0mdistances\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_distance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maq_lat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maq_lon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdistances\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdistances\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-59-f34700b61b9c>\u001b[0m in \u001b[0;36mget_distance\u001b[0;34m(aq_lat, aq_lon, weather_lat, weather_lon)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# return numerical distance between two lat lon points\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_distance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maq_lat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maq_lon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweather_lat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweather_lon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mdist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maq_lat\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mweather_lat\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0maq_lon\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mweather_lon\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdist\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'math' is not defined"
     ]
    }
   ],
   "source": [
    "# note: this cell takes a long time\n",
    "# for each pollutant, prepare a cleaned dataframe with land use\n",
    "# dataframes list ends up with order: 'CO', 'SO', 'NO', 'OZO', 'PM'\n",
    "\n",
    "sites = LU['Site']\n",
    "dataframes = np.zeros(5, dtype=pd.DataFrame)\n",
    "\n",
    "for i in range(0,5):\n",
    "\n",
    "    filename = local_path + 'appended' + pollutants[i] + '.csv'\n",
    "    \n",
    "    AQ = pd.read_csv(filename)\n",
    "    \n",
    "    lat = AQ['Latitude']\n",
    "    lon = AQ['Longitude']\n",
    "    AQ['lat_lon'] = list(zip(lat, lon))\n",
    "    pts = AQ['lat_lon']\n",
    "    \n",
    "    AQ_width = AQ.shape[1]\n",
    "\n",
    "    AQ = add_columns(AQ)\n",
    "\n",
    "    for pt in range(len(AQ['lat_lon'])):\n",
    "        for cell in range(len(sites)):\n",
    "            if in_cell(pts[pt][1], pts[pt][0], LU['Site'][cell]):\n",
    "                # add cell info to appendedAQ.csv file\n",
    "                AQ = update_proportions(AQ, LU, pt, cell)\n",
    "        weather_index = find_sensor(pts[pt][0], pts[pt][1])\n",
    "        AQ = fill_in_weather(AQ, LU, pt, weather_index)\n",
    "    \n",
    "    dataframes[i] = AQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Singleton array array(0) cannot be considered a valid collection.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-62-54e6031402b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mAQ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataframes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msplit_train_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAQ\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0my_train_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msimple_gaussian\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malphas\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-60-9e75e4bb1456>\u001b[0m in \u001b[0;36msplit_train_test\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\"\"\"Splits dataframe into train and test data\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0msplit_train_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m.30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mx_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Sample Collection Start Time\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0my_train\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Measure Value\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Annamira/anaconda/lib/python3.6/site-packages/sklearn/model_selection/_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[0;34m(*arrays, **options)\u001b[0m\n\u001b[1;32m   1687\u001b[0m         \u001b[0mtest_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.25\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1688\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1689\u001b[0;31m     \u001b[0marrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marrays\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1690\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1691\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mstratify\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Annamira/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mindexable\u001b[0;34m(*iterables)\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Annamira/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    175\u001b[0m     \"\"\"\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m     \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Annamira/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    175\u001b[0m     \"\"\"\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m     \u001b[0mlengths\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0m_num_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32min\u001b[0m \u001b[0marrays\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m     \u001b[0muniques\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munique\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/Annamira/anaconda/lib/python3.6/site-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36m_num_samples\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m             raise TypeError(\"Singleton array %r cannot be considered\"\n\u001b[0;32m--> 126\u001b[0;31m                             \" a valid collection.\" % x)\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Singleton array array(0) cannot be considered a valid collection."
     ]
    }
   ],
   "source": [
    "# for each pollutant, do a gaussian process\n",
    "\n",
    "for i in range(0,5):\n",
    "    \n",
    "    AQ = dataframes[i]\n",
    "    \n",
    "    x_train, y_train, x_test, y_test = split_train_test(AQ)\n",
    "\n",
    "    y_train_pred, y_test_pred, gp = simple_gaussian(x_train, y_train, x_test, y_test, alphas[i])\n",
    "\n",
    "    plot_predictions(x_test, y_test, y_test_pred, x_label, y_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
