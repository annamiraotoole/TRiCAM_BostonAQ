{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taraippolito/anaconda/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn as sk\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.linear_model import BayesianRidge\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import statsmodels.api as sm\n",
    "sns.set(style=\"ticks\")\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "comm_data_df = pd.read_csv('communities.data.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>8</th>\n",
       "      <th>?</th>\n",
       "      <th>?.1</th>\n",
       "      <th>Lakewoodcity</th>\n",
       "      <th>1</th>\n",
       "      <th>0.19</th>\n",
       "      <th>0.33</th>\n",
       "      <th>0.02</th>\n",
       "      <th>0.9</th>\n",
       "      <th>0.12</th>\n",
       "      <th>...</th>\n",
       "      <th>0.12.2</th>\n",
       "      <th>0.26.1</th>\n",
       "      <th>0.2.1</th>\n",
       "      <th>0.06.3</th>\n",
       "      <th>0.04.2</th>\n",
       "      <th>0.9.1</th>\n",
       "      <th>0.5.2</th>\n",
       "      <th>0.32.2</th>\n",
       "      <th>0.14.3</th>\n",
       "      <th>0.2.2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>53</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>Tukwilacity</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.45</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.45</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>0.0</td>\n",
       "      <td>?</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>24</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>Aberdeentown</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.17</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.02</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>0.0</td>\n",
       "      <td>?</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34</td>\n",
       "      <td>5</td>\n",
       "      <td>81440</td>\n",
       "      <td>Willingborotownship</td>\n",
       "      <td>1</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.12</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.28</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>0.0</td>\n",
       "      <td>?</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>42</td>\n",
       "      <td>95</td>\n",
       "      <td>6096</td>\n",
       "      <td>Bethlehemtownship</td>\n",
       "      <td>1</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.09</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.02</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>0.0</td>\n",
       "      <td>?</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>SouthPasadenacity</td>\n",
       "      <td>1</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.54</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.10</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>?</td>\n",
       "      <td>0.0</td>\n",
       "      <td>?</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 128 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    8   ?    ?.1         Lakewoodcity  1  0.19  0.33  0.02   0.9  0.12  ...    \\\n",
       "0  53   ?      ?          Tukwilacity  1  0.00  0.16  0.12  0.74  0.45  ...     \n",
       "1  24   ?      ?         Aberdeentown  1  0.00  0.42  0.49  0.56  0.17  ...     \n",
       "2  34   5  81440  Willingborotownship  1  0.04  0.77  1.00  0.08  0.12  ...     \n",
       "3  42  95   6096    Bethlehemtownship  1  0.01  0.55  0.02  0.95  0.09  ...     \n",
       "4   6   ?      ?    SouthPasadenacity  1  0.02  0.28  0.06  0.54  1.00  ...     \n",
       "\n",
       "   0.12.2  0.26.1  0.2.1  0.06.3  0.04.2  0.9.1  0.5.2  0.32.2  0.14.3  0.2.2  \n",
       "0    0.02    0.12   0.45       ?       ?      ?      ?     0.0       ?   0.67  \n",
       "1    0.01    0.21   0.02       ?       ?      ?      ?     0.0       ?   0.43  \n",
       "2    0.02    0.39   0.28       ?       ?      ?      ?     0.0       ?   0.12  \n",
       "3    0.04    0.09   0.02       ?       ?      ?      ?     0.0       ?   0.03  \n",
       "4    0.01    0.58   0.10       ?       ?      ?      ?     0.0       ?   0.14  \n",
       "\n",
       "[5 rows x 128 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comm_data_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1994, 128)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comm_data_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fix question marks\n",
    "\n",
    "for c in range(1, 127):\n",
    "    for r in range(0, 1994):\n",
    "        if comm_data_df[c][r] == '?':\n",
    "            comm_data_df.set_value(r, c, 0)\n",
    "\n",
    "for c in range(4, 127):\n",
    "    for r in range(0, 1994):\n",
    "        if type(comm_data_df[c][r]) == str:\n",
    "            comm_data_df.set_value(r, c, float(comm_data_df[c][r]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = comm_data_df.iloc[:, 4:126]\n",
    "target = comm_data_df.iloc[:, 127]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'target' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-585917548d1a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m#makes predictions for y based on x\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mreturn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msummary\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mreg_m\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'target' is not defined"
     ]
    }
   ],
   "source": [
    "def reg_m(y, x):\n",
    "    model = sm.OLS(y, x.astype(float)).fit()\n",
    "    #fits simple ordinary least squares model\n",
    "    predictions = model.predict(x)\n",
    "    #makes predictions for y based on x\n",
    "    return(model.summary())\n",
    "reg_m(target, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test= train_test_split(x, target, test_size=0.30, random_state=0)\n",
    "# x_train = np."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.861</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.847</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   64.43</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 03 Jul 2017</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:05:57</td>     <th>  Log-Likelihood:    </th> <td>  922.02</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1395</td>      <th>  AIC:               </th> <td>  -1600.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1273</td>      <th>  BIC:               </th> <td>  -960.7</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>   122</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>      <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>   <td>   -0.0028</td> <td>    0.001</td> <td>   -2.171</td> <td> 0.030</td> <td>   -0.005</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>   <td>    0.2655</td> <td>    0.477</td> <td>    0.557</td> <td> 0.578</td> <td>   -0.670</td> <td>    1.201</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>   <td>    0.0628</td> <td>    0.103</td> <td>    0.608</td> <td> 0.544</td> <td>   -0.140</td> <td>    0.266</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>   <td>    0.2417</td> <td>    0.064</td> <td>    3.787</td> <td> 0.000</td> <td>    0.116</td> <td>    0.367</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>   <td>    0.0066</td> <td>    0.073</td> <td>    0.091</td> <td> 0.928</td> <td>   -0.136</td> <td>    0.149</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>   <td>   -0.0180</td> <td>    0.043</td> <td>   -0.422</td> <td> 0.673</td> <td>   -0.101</td> <td>    0.066</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>   <td>    0.0938</td> <td>    0.064</td> <td>    1.465</td> <td> 0.143</td> <td>   -0.032</td> <td>    0.220</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>   <td>    0.1548</td> <td>    0.124</td> <td>    1.246</td> <td> 0.213</td> <td>   -0.089</td> <td>    0.398</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>   <td>   -0.1347</td> <td>    0.184</td> <td>   -0.733</td> <td> 0.464</td> <td>   -0.495</td> <td>    0.226</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>  <td>   -0.2221</td> <td>    0.196</td> <td>   -1.131</td> <td> 0.258</td> <td>   -0.607</td> <td>    0.163</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>  <td>    0.1749</td> <td>    0.116</td> <td>    1.503</td> <td> 0.133</td> <td>   -0.053</td> <td>    0.403</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>  <td>   -0.3429</td> <td>    0.470</td> <td>   -0.729</td> <td> 0.466</td> <td>   -1.265</td> <td>    0.579</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>  <td>    0.0540</td> <td>    0.019</td> <td>    2.831</td> <td> 0.005</td> <td>    0.017</td> <td>    0.091</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>  <td>   -0.2114</td> <td>    0.208</td> <td>   -1.017</td> <td> 0.309</td> <td>   -0.619</td> <td>    0.196</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>  <td>   -0.0981</td> <td>    0.102</td> <td>   -0.966</td> <td> 0.334</td> <td>   -0.297</td> <td>    0.101</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>  <td>    0.0419</td> <td>    0.024</td> <td>    1.748</td> <td> 0.081</td> <td>   -0.005</td> <td>    0.089</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th>  <td>   -0.1582</td> <td>    0.084</td> <td>   -1.888</td> <td> 0.059</td> <td>   -0.323</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th>  <td>    0.1544</td> <td>    0.129</td> <td>    1.200</td> <td> 0.230</td> <td>   -0.098</td> <td>    0.407</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19</th>  <td>    0.0943</td> <td>    0.056</td> <td>    1.689</td> <td> 0.092</td> <td>   -0.015</td> <td>    0.204</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20</th>  <td>   -0.0668</td> <td>    0.045</td> <td>   -1.490</td> <td> 0.137</td> <td>   -0.155</td> <td>    0.021</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21</th>  <td>    0.2376</td> <td>    0.195</td> <td>    1.221</td> <td> 0.222</td> <td>   -0.144</td> <td>    0.619</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22</th>  <td>    0.0999</td> <td>    0.243</td> <td>    0.410</td> <td> 0.682</td> <td>   -0.378</td> <td>    0.578</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23</th>  <td>   -0.2413</td> <td>    0.208</td> <td>   -1.162</td> <td> 0.245</td> <td>   -0.649</td> <td>    0.166</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24</th>  <td>   -0.0224</td> <td>    0.031</td> <td>   -0.730</td> <td> 0.466</td> <td>   -0.083</td> <td>    0.038</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x25</th>  <td>   -0.0353</td> <td>    0.023</td> <td>   -1.506</td> <td> 0.132</td> <td>   -0.081</td> <td>    0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x26</th>  <td>    0.0321</td> <td>    0.024</td> <td>    1.355</td> <td> 0.176</td> <td>   -0.014</td> <td>    0.079</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x27</th>  <td>    0.0300</td> <td>    0.023</td> <td>    1.325</td> <td> 0.186</td> <td>   -0.014</td> <td>    0.074</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x28</th>  <td>    0.0235</td> <td>    0.030</td> <td>    0.789</td> <td> 0.430</td> <td>   -0.035</td> <td>    0.082</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x29</th>  <td>    0.0920</td> <td>    0.190</td> <td>    0.484</td> <td> 0.628</td> <td>   -0.281</td> <td>    0.465</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x30</th>  <td>   -0.1554</td> <td>    0.074</td> <td>   -2.113</td> <td> 0.035</td> <td>   -0.300</td> <td>   -0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x31</th>  <td>   -0.0831</td> <td>    0.083</td> <td>   -0.999</td> <td> 0.318</td> <td>   -0.246</td> <td>    0.080</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x32</th>  <td>    0.0287</td> <td>    0.115</td> <td>    0.249</td> <td> 0.803</td> <td>   -0.197</td> <td>    0.254</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x33</th>  <td>    0.0524</td> <td>    0.094</td> <td>    0.559</td> <td> 0.576</td> <td>   -0.132</td> <td>    0.236</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x34</th>  <td>    0.0368</td> <td>    0.049</td> <td>    0.757</td> <td> 0.449</td> <td>   -0.058</td> <td>    0.132</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x35</th>  <td>    0.3446</td> <td>    0.091</td> <td>    3.785</td> <td> 0.000</td> <td>    0.166</td> <td>    0.523</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x36</th>  <td>   -0.0972</td> <td>    0.040</td> <td>   -2.457</td> <td> 0.014</td> <td>   -0.175</td> <td>   -0.020</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x37</th>  <td>   -0.0544</td> <td>    0.050</td> <td>   -1.094</td> <td> 0.274</td> <td>   -0.152</td> <td>    0.043</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x38</th>  <td>    0.1239</td> <td>    0.066</td> <td>    1.866</td> <td> 0.062</td> <td>   -0.006</td> <td>    0.254</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x39</th>  <td>    0.1370</td> <td>    0.106</td> <td>    1.299</td> <td> 0.194</td> <td>   -0.070</td> <td>    0.344</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x40</th>  <td>    0.3985</td> <td>    0.285</td> <td>    1.397</td> <td> 0.163</td> <td>   -0.161</td> <td>    0.958</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x41</th>  <td>    0.2197</td> <td>    0.084</td> <td>    2.607</td> <td> 0.009</td> <td>    0.054</td> <td>    0.385</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x42</th>  <td>   -0.0060</td> <td>    0.347</td> <td>   -0.017</td> <td> 0.986</td> <td>   -0.687</td> <td>    0.675</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x43</th>  <td>   -0.3245</td> <td>    0.587</td> <td>   -0.553</td> <td> 0.581</td> <td>   -1.477</td> <td>    0.827</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x44</th>  <td>   -0.0387</td> <td>    0.207</td> <td>   -0.187</td> <td> 0.851</td> <td>   -0.444</td> <td>    0.367</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x45</th>  <td>   -0.0840</td> <td>    0.193</td> <td>   -0.435</td> <td> 0.664</td> <td>   -0.463</td> <td>    0.295</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x46</th>  <td>   -0.2648</td> <td>    0.186</td> <td>   -1.425</td> <td> 0.155</td> <td>   -0.629</td> <td>    0.100</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x47</th>  <td>    0.0305</td> <td>    0.058</td> <td>    0.528</td> <td> 0.597</td> <td>   -0.083</td> <td>    0.144</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x48</th>  <td>    0.0054</td> <td>    0.051</td> <td>    0.106</td> <td> 0.916</td> <td>   -0.094</td> <td>    0.105</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x49</th>  <td>    0.0977</td> <td>    0.056</td> <td>    1.746</td> <td> 0.081</td> <td>   -0.012</td> <td>    0.208</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x50</th>  <td>   -0.2458</td> <td>    0.064</td> <td>   -3.838</td> <td> 0.000</td> <td>   -0.371</td> <td>   -0.120</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x51</th>  <td>   -0.2707</td> <td>    0.188</td> <td>   -1.436</td> <td> 0.151</td> <td>   -0.640</td> <td>    0.099</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x52</th>  <td>    0.1233</td> <td>    0.057</td> <td>    2.163</td> <td> 0.031</td> <td>    0.011</td> <td>    0.235</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x53</th>  <td>   -0.1620</td> <td>    0.117</td> <td>   -1.390</td> <td> 0.165</td> <td>   -0.391</td> <td>    0.067</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x54</th>  <td>   -0.0315</td> <td>    0.051</td> <td>   -0.616</td> <td> 0.538</td> <td>   -0.132</td> <td>    0.069</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x55</th>  <td>    0.1263</td> <td>    0.079</td> <td>    1.595</td> <td> 0.111</td> <td>   -0.029</td> <td>    0.282</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x56</th>  <td>   -0.1238</td> <td>    0.089</td> <td>   -1.387</td> <td> 0.166</td> <td>   -0.299</td> <td>    0.051</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x57</th>  <td>    0.0650</td> <td>    0.071</td> <td>    0.915</td> <td> 0.360</td> <td>   -0.074</td> <td>    0.204</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x58</th>  <td>    0.0468</td> <td>    0.156</td> <td>    0.300</td> <td> 0.764</td> <td>   -0.259</td> <td>    0.353</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x59</th>  <td>   -0.2570</td> <td>    0.275</td> <td>   -0.936</td> <td> 0.349</td> <td>   -0.796</td> <td>    0.282</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x60</th>  <td>    0.6461</td> <td>    0.335</td> <td>    1.926</td> <td> 0.054</td> <td>   -0.012</td> <td>    1.304</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x61</th>  <td>   -0.4027</td> <td>    0.276</td> <td>   -1.459</td> <td> 0.145</td> <td>   -0.944</td> <td>    0.139</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x62</th>  <td>   -0.0497</td> <td>    0.078</td> <td>   -0.634</td> <td> 0.526</td> <td>   -0.204</td> <td>    0.104</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x63</th>  <td>   -0.1776</td> <td>    0.084</td> <td>   -2.114</td> <td> 0.035</td> <td>   -0.342</td> <td>   -0.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x64</th>  <td>   -0.2225</td> <td>    0.280</td> <td>   -0.794</td> <td> 0.427</td> <td>   -0.772</td> <td>    0.327</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x65</th>  <td>   -0.0577</td> <td>    0.288</td> <td>   -0.201</td> <td> 0.841</td> <td>   -0.622</td> <td>    0.507</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x66</th>  <td>    0.4222</td> <td>    0.307</td> <td>    1.376</td> <td> 0.169</td> <td>   -0.180</td> <td>    1.024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x67</th>  <td>    0.0760</td> <td>    0.206</td> <td>    0.369</td> <td> 0.712</td> <td>   -0.328</td> <td>    0.480</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x68</th>  <td>   -0.1405</td> <td>    0.098</td> <td>   -1.431</td> <td> 0.153</td> <td>   -0.333</td> <td>    0.052</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x69</th>  <td>   -0.5182</td> <td>    0.442</td> <td>   -1.172</td> <td> 0.241</td> <td>   -1.385</td> <td>    0.349</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x70</th>  <td>    0.1958</td> <td>    0.089</td> <td>    2.211</td> <td> 0.027</td> <td>    0.022</td> <td>    0.370</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x71</th>  <td>    0.2134</td> <td>    0.068</td> <td>    3.146</td> <td> 0.002</td> <td>    0.080</td> <td>    0.346</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x72</th>  <td>    0.0431</td> <td>    0.024</td> <td>    1.815</td> <td> 0.070</td> <td>   -0.003</td> <td>    0.090</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x73</th>  <td>    0.1912</td> <td>    0.086</td> <td>    2.213</td> <td> 0.027</td> <td>    0.022</td> <td>    0.361</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x74</th>  <td>   -0.0209</td> <td>    0.037</td> <td>   -0.572</td> <td> 0.568</td> <td>   -0.093</td> <td>    0.051</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x75</th>  <td>    0.4918</td> <td>    0.462</td> <td>    1.065</td> <td> 0.287</td> <td>   -0.414</td> <td>    1.398</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x76</th>  <td>    0.0811</td> <td>    0.027</td> <td>    3.034</td> <td> 0.002</td> <td>    0.029</td> <td>    0.134</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x77</th>  <td>   -0.0553</td> <td>    0.030</td> <td>   -1.866</td> <td> 0.062</td> <td>   -0.113</td> <td>    0.003</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x78</th>  <td>   -0.0037</td> <td>    0.035</td> <td>   -0.106</td> <td> 0.916</td> <td>   -0.073</td> <td>    0.066</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x79</th>  <td>   -0.0177</td> <td>    0.043</td> <td>   -0.412</td> <td> 0.680</td> <td>   -0.102</td> <td>    0.067</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x80</th>  <td>   -0.0441</td> <td>    0.025</td> <td>   -1.735</td> <td> 0.083</td> <td>   -0.094</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x81</th>  <td>   -0.4555</td> <td>    0.258</td> <td>   -1.768</td> <td> 0.077</td> <td>   -0.961</td> <td>    0.050</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x82</th>  <td>    0.5191</td> <td>    0.393</td> <td>    1.319</td> <td> 0.187</td> <td>   -0.253</td> <td>    1.291</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x83</th>  <td>   -0.1478</td> <td>    0.205</td> <td>   -0.719</td> <td> 0.472</td> <td>   -0.551</td> <td>    0.255</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x84</th>  <td>   -0.2772</td> <td>    0.084</td> <td>   -3.298</td> <td> 0.001</td> <td>   -0.442</td> <td>   -0.112</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x85</th>  <td>    0.0832</td> <td>    0.193</td> <td>    0.431</td> <td> 0.667</td> <td>   -0.296</td> <td>    0.462</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x86</th>  <td>   -0.0710</td> <td>    0.109</td> <td>   -0.649</td> <td> 0.516</td> <td>   -0.286</td> <td>    0.144</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x87</th>  <td>    0.3356</td> <td>    0.152</td> <td>    2.206</td> <td> 0.028</td> <td>    0.037</td> <td>    0.634</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x88</th>  <td>    0.0778</td> <td>    0.041</td> <td>    1.899</td> <td> 0.058</td> <td>   -0.003</td> <td>    0.158</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x89</th>  <td>   -0.0662</td> <td>    0.042</td> <td>   -1.592</td> <td> 0.112</td> <td>   -0.148</td> <td>    0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x90</th>  <td>   -0.1115</td> <td>    0.030</td> <td>   -3.759</td> <td> 0.000</td> <td>   -0.170</td> <td>   -0.053</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x91</th>  <td>    0.0898</td> <td>    0.092</td> <td>    0.980</td> <td> 0.327</td> <td>   -0.090</td> <td>    0.269</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x92</th>  <td>    0.1322</td> <td>    0.059</td> <td>    2.251</td> <td> 0.025</td> <td>    0.017</td> <td>    0.247</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x93</th>  <td>    0.0661</td> <td>    0.109</td> <td>    0.604</td> <td> 0.546</td> <td>   -0.149</td> <td>    0.281</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x94</th>  <td>    0.0460</td> <td>    0.052</td> <td>    0.883</td> <td> 0.377</td> <td>   -0.056</td> <td>    0.148</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x95</th>  <td>   -0.0559</td> <td>    0.072</td> <td>   -0.781</td> <td> 0.435</td> <td>   -0.196</td> <td>    0.084</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x96</th>  <td>    0.0180</td> <td>    0.046</td> <td>    0.391</td> <td> 0.696</td> <td>   -0.072</td> <td>    0.108</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x97</th>  <td>   -0.0014</td> <td>    0.052</td> <td>   -0.026</td> <td> 0.979</td> <td>   -0.104</td> <td>    0.101</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x98</th>  <td>    0.1096</td> <td>    0.405</td> <td>    0.271</td> <td> 0.787</td> <td>   -0.685</td> <td>    0.904</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x99</th>  <td>  -19.2666</td> <td>   14.465</td> <td>   -1.332</td> <td> 0.183</td> <td>  -47.645</td> <td>    9.112</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x100</th> <td>    0.0777</td> <td>    0.099</td> <td>    0.783</td> <td> 0.434</td> <td>   -0.117</td> <td>    0.272</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x101</th> <td>    0.5621</td> <td>    0.426</td> <td>    1.318</td> <td> 0.188</td> <td>   -0.275</td> <td>    1.399</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x102</th> <td>   -0.1884</td> <td>    0.201</td> <td>   -0.937</td> <td> 0.349</td> <td>   -0.583</td> <td>    0.206</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x103</th> <td>    0.0089</td> <td>    0.178</td> <td>    0.050</td> <td> 0.960</td> <td>   -0.341</td> <td>    0.359</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x104</th> <td>    0.1616</td> <td>    0.111</td> <td>    1.458</td> <td> 0.145</td> <td>   -0.056</td> <td>    0.379</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x105</th> <td>   18.8439</td> <td>   14.441</td> <td>    1.305</td> <td> 0.192</td> <td>   -9.486</td> <td>   47.174</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x106</th> <td>   -0.1156</td> <td>    0.053</td> <td>   -2.178</td> <td> 0.030</td> <td>   -0.220</td> <td>   -0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x107</th> <td>   -0.0365</td> <td>    0.094</td> <td>   -0.390</td> <td> 0.696</td> <td>   -0.220</td> <td>    0.147</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x108</th> <td>    0.1482</td> <td>    0.173</td> <td>    0.856</td> <td> 0.392</td> <td>   -0.192</td> <td>    0.488</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x109</th> <td>    0.2604</td> <td>    0.188</td> <td>    1.389</td> <td> 0.165</td> <td>   -0.107</td> <td>    0.628</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x110</th> <td>    0.0682</td> <td>    0.057</td> <td>    1.195</td> <td> 0.232</td> <td>   -0.044</td> <td>    0.180</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x111</th> <td>   -0.2227</td> <td>    0.250</td> <td>   -0.892</td> <td> 0.373</td> <td>   -0.712</td> <td>    0.267</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x112</th> <td>    0.1087</td> <td>    0.257</td> <td>    0.424</td> <td> 0.672</td> <td>   -0.395</td> <td>    0.612</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x113</th> <td>    0.0333</td> <td>    0.047</td> <td>    0.704</td> <td> 0.482</td> <td>   -0.059</td> <td>    0.126</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x114</th> <td>   -0.0177</td> <td>    0.042</td> <td>   -0.416</td> <td> 0.678</td> <td>   -0.101</td> <td>    0.066</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x115</th> <td>    0.0682</td> <td>    0.070</td> <td>    0.971</td> <td> 0.332</td> <td>   -0.070</td> <td>    0.206</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x116</th> <td>    0.0076</td> <td>    0.038</td> <td>    0.201</td> <td> 0.840</td> <td>   -0.066</td> <td>    0.081</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x117</th> <td>   -0.0212</td> <td>    0.029</td> <td>   -0.742</td> <td> 0.458</td> <td>   -0.077</td> <td>    0.035</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x118</th> <td>    0.0038</td> <td>    0.090</td> <td>    0.042</td> <td> 0.967</td> <td>   -0.173</td> <td>    0.180</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x119</th> <td>    0.1911</td> <td>    0.310</td> <td>    0.617</td> <td> 0.537</td> <td>   -0.417</td> <td>    0.799</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x120</th> <td>   -0.0352</td> <td>    0.082</td> <td>   -0.427</td> <td> 0.670</td> <td>   -0.197</td> <td>    0.126</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x121</th> <td>    0.0173</td> <td>    0.023</td> <td>    0.744</td> <td> 0.457</td> <td>   -0.028</td> <td>    0.063</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x122</th> <td>   -0.0863</td> <td>    0.048</td> <td>   -1.797</td> <td> 0.073</td> <td>   -0.180</td> <td>    0.008</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>233.220</td> <th>  Durbin-Watson:     </th> <td>   1.934</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 665.128</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.860</td>  <th>  Prob(JB):          </th> <td>3.71e-145</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.912</td>  <th>  Cond. No.          </th> <td>4.24e+04</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.861\n",
       "Model:                            OLS   Adj. R-squared:                  0.847\n",
       "Method:                 Least Squares   F-statistic:                     64.43\n",
       "Date:                Mon, 03 Jul 2017   Prob (F-statistic):               0.00\n",
       "Time:                        10:05:57   Log-Likelihood:                 922.02\n",
       "No. Observations:                1395   AIC:                            -1600.\n",
       "Df Residuals:                    1273   BIC:                            -960.7\n",
       "Df Model:                         122                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "x1            -0.0028      0.001     -2.171      0.030      -0.005      -0.000\n",
       "x2             0.2655      0.477      0.557      0.578      -0.670       1.201\n",
       "x3             0.0628      0.103      0.608      0.544      -0.140       0.266\n",
       "x4             0.2417      0.064      3.787      0.000       0.116       0.367\n",
       "x5             0.0066      0.073      0.091      0.928      -0.136       0.149\n",
       "x6            -0.0180      0.043     -0.422      0.673      -0.101       0.066\n",
       "x7             0.0938      0.064      1.465      0.143      -0.032       0.220\n",
       "x8             0.1548      0.124      1.246      0.213      -0.089       0.398\n",
       "x9            -0.1347      0.184     -0.733      0.464      -0.495       0.226\n",
       "x10           -0.2221      0.196     -1.131      0.258      -0.607       0.163\n",
       "x11            0.1749      0.116      1.503      0.133      -0.053       0.403\n",
       "x12           -0.3429      0.470     -0.729      0.466      -1.265       0.579\n",
       "x13            0.0540      0.019      2.831      0.005       0.017       0.091\n",
       "x14           -0.2114      0.208     -1.017      0.309      -0.619       0.196\n",
       "x15           -0.0981      0.102     -0.966      0.334      -0.297       0.101\n",
       "x16            0.0419      0.024      1.748      0.081      -0.005       0.089\n",
       "x17           -0.1582      0.084     -1.888      0.059      -0.323       0.006\n",
       "x18            0.1544      0.129      1.200      0.230      -0.098       0.407\n",
       "x19            0.0943      0.056      1.689      0.092      -0.015       0.204\n",
       "x20           -0.0668      0.045     -1.490      0.137      -0.155       0.021\n",
       "x21            0.2376      0.195      1.221      0.222      -0.144       0.619\n",
       "x22            0.0999      0.243      0.410      0.682      -0.378       0.578\n",
       "x23           -0.2413      0.208     -1.162      0.245      -0.649       0.166\n",
       "x24           -0.0224      0.031     -0.730      0.466      -0.083       0.038\n",
       "x25           -0.0353      0.023     -1.506      0.132      -0.081       0.011\n",
       "x26            0.0321      0.024      1.355      0.176      -0.014       0.079\n",
       "x27            0.0300      0.023      1.325      0.186      -0.014       0.074\n",
       "x28            0.0235      0.030      0.789      0.430      -0.035       0.082\n",
       "x29            0.0920      0.190      0.484      0.628      -0.281       0.465\n",
       "x30           -0.1554      0.074     -2.113      0.035      -0.300      -0.011\n",
       "x31           -0.0831      0.083     -0.999      0.318      -0.246       0.080\n",
       "x32            0.0287      0.115      0.249      0.803      -0.197       0.254\n",
       "x33            0.0524      0.094      0.559      0.576      -0.132       0.236\n",
       "x34            0.0368      0.049      0.757      0.449      -0.058       0.132\n",
       "x35            0.3446      0.091      3.785      0.000       0.166       0.523\n",
       "x36           -0.0972      0.040     -2.457      0.014      -0.175      -0.020\n",
       "x37           -0.0544      0.050     -1.094      0.274      -0.152       0.043\n",
       "x38            0.1239      0.066      1.866      0.062      -0.006       0.254\n",
       "x39            0.1370      0.106      1.299      0.194      -0.070       0.344\n",
       "x40            0.3985      0.285      1.397      0.163      -0.161       0.958\n",
       "x41            0.2197      0.084      2.607      0.009       0.054       0.385\n",
       "x42           -0.0060      0.347     -0.017      0.986      -0.687       0.675\n",
       "x43           -0.3245      0.587     -0.553      0.581      -1.477       0.827\n",
       "x44           -0.0387      0.207     -0.187      0.851      -0.444       0.367\n",
       "x45           -0.0840      0.193     -0.435      0.664      -0.463       0.295\n",
       "x46           -0.2648      0.186     -1.425      0.155      -0.629       0.100\n",
       "x47            0.0305      0.058      0.528      0.597      -0.083       0.144\n",
       "x48            0.0054      0.051      0.106      0.916      -0.094       0.105\n",
       "x49            0.0977      0.056      1.746      0.081      -0.012       0.208\n",
       "x50           -0.2458      0.064     -3.838      0.000      -0.371      -0.120\n",
       "x51           -0.2707      0.188     -1.436      0.151      -0.640       0.099\n",
       "x52            0.1233      0.057      2.163      0.031       0.011       0.235\n",
       "x53           -0.1620      0.117     -1.390      0.165      -0.391       0.067\n",
       "x54           -0.0315      0.051     -0.616      0.538      -0.132       0.069\n",
       "x55            0.1263      0.079      1.595      0.111      -0.029       0.282\n",
       "x56           -0.1238      0.089     -1.387      0.166      -0.299       0.051\n",
       "x57            0.0650      0.071      0.915      0.360      -0.074       0.204\n",
       "x58            0.0468      0.156      0.300      0.764      -0.259       0.353\n",
       "x59           -0.2570      0.275     -0.936      0.349      -0.796       0.282\n",
       "x60            0.6461      0.335      1.926      0.054      -0.012       1.304\n",
       "x61           -0.4027      0.276     -1.459      0.145      -0.944       0.139\n",
       "x62           -0.0497      0.078     -0.634      0.526      -0.204       0.104\n",
       "x63           -0.1776      0.084     -2.114      0.035      -0.342      -0.013\n",
       "x64           -0.2225      0.280     -0.794      0.427      -0.772       0.327\n",
       "x65           -0.0577      0.288     -0.201      0.841      -0.622       0.507\n",
       "x66            0.4222      0.307      1.376      0.169      -0.180       1.024\n",
       "x67            0.0760      0.206      0.369      0.712      -0.328       0.480\n",
       "x68           -0.1405      0.098     -1.431      0.153      -0.333       0.052\n",
       "x69           -0.5182      0.442     -1.172      0.241      -1.385       0.349\n",
       "x70            0.1958      0.089      2.211      0.027       0.022       0.370\n",
       "x71            0.2134      0.068      3.146      0.002       0.080       0.346\n",
       "x72            0.0431      0.024      1.815      0.070      -0.003       0.090\n",
       "x73            0.1912      0.086      2.213      0.027       0.022       0.361\n",
       "x74           -0.0209      0.037     -0.572      0.568      -0.093       0.051\n",
       "x75            0.4918      0.462      1.065      0.287      -0.414       1.398\n",
       "x76            0.0811      0.027      3.034      0.002       0.029       0.134\n",
       "x77           -0.0553      0.030     -1.866      0.062      -0.113       0.003\n",
       "x78           -0.0037      0.035     -0.106      0.916      -0.073       0.066\n",
       "x79           -0.0177      0.043     -0.412      0.680      -0.102       0.067\n",
       "x80           -0.0441      0.025     -1.735      0.083      -0.094       0.006\n",
       "x81           -0.4555      0.258     -1.768      0.077      -0.961       0.050\n",
       "x82            0.5191      0.393      1.319      0.187      -0.253       1.291\n",
       "x83           -0.1478      0.205     -0.719      0.472      -0.551       0.255\n",
       "x84           -0.2772      0.084     -3.298      0.001      -0.442      -0.112\n",
       "x85            0.0832      0.193      0.431      0.667      -0.296       0.462\n",
       "x86           -0.0710      0.109     -0.649      0.516      -0.286       0.144\n",
       "x87            0.3356      0.152      2.206      0.028       0.037       0.634\n",
       "x88            0.0778      0.041      1.899      0.058      -0.003       0.158\n",
       "x89           -0.0662      0.042     -1.592      0.112      -0.148       0.015\n",
       "x90           -0.1115      0.030     -3.759      0.000      -0.170      -0.053\n",
       "x91            0.0898      0.092      0.980      0.327      -0.090       0.269\n",
       "x92            0.1322      0.059      2.251      0.025       0.017       0.247\n",
       "x93            0.0661      0.109      0.604      0.546      -0.149       0.281\n",
       "x94            0.0460      0.052      0.883      0.377      -0.056       0.148\n",
       "x95           -0.0559      0.072     -0.781      0.435      -0.196       0.084\n",
       "x96            0.0180      0.046      0.391      0.696      -0.072       0.108\n",
       "x97           -0.0014      0.052     -0.026      0.979      -0.104       0.101\n",
       "x98            0.1096      0.405      0.271      0.787      -0.685       0.904\n",
       "x99          -19.2666     14.465     -1.332      0.183     -47.645       9.112\n",
       "x100           0.0777      0.099      0.783      0.434      -0.117       0.272\n",
       "x101           0.5621      0.426      1.318      0.188      -0.275       1.399\n",
       "x102          -0.1884      0.201     -0.937      0.349      -0.583       0.206\n",
       "x103           0.0089      0.178      0.050      0.960      -0.341       0.359\n",
       "x104           0.1616      0.111      1.458      0.145      -0.056       0.379\n",
       "x105          18.8439     14.441      1.305      0.192      -9.486      47.174\n",
       "x106          -0.1156      0.053     -2.178      0.030      -0.220      -0.011\n",
       "x107          -0.0365      0.094     -0.390      0.696      -0.220       0.147\n",
       "x108           0.1482      0.173      0.856      0.392      -0.192       0.488\n",
       "x109           0.2604      0.188      1.389      0.165      -0.107       0.628\n",
       "x110           0.0682      0.057      1.195      0.232      -0.044       0.180\n",
       "x111          -0.2227      0.250     -0.892      0.373      -0.712       0.267\n",
       "x112           0.1087      0.257      0.424      0.672      -0.395       0.612\n",
       "x113           0.0333      0.047      0.704      0.482      -0.059       0.126\n",
       "x114          -0.0177      0.042     -0.416      0.678      -0.101       0.066\n",
       "x115           0.0682      0.070      0.971      0.332      -0.070       0.206\n",
       "x116           0.0076      0.038      0.201      0.840      -0.066       0.081\n",
       "x117          -0.0212      0.029     -0.742      0.458      -0.077       0.035\n",
       "x118           0.0038      0.090      0.042      0.967      -0.173       0.180\n",
       "x119           0.1911      0.310      0.617      0.537      -0.417       0.799\n",
       "x120          -0.0352      0.082     -0.427      0.670      -0.197       0.126\n",
       "x121           0.0173      0.023      0.744      0.457      -0.028       0.063\n",
       "x122          -0.0863      0.048     -1.797      0.073      -0.180       0.008\n",
       "==============================================================================\n",
       "Omnibus:                      233.220   Durbin-Watson:                   1.934\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              665.128\n",
       "Skew:                           0.860   Prob(JB):                    3.71e-145\n",
       "Kurtosis:                       5.912   Cond. No.                     4.24e+04\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 4.24e+04. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_m(np.asarray(y_train), np.asarray(x_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.868</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.834</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   25.94</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Mon, 03 Jul 2017</td> <th>  Prob (F-statistic):</th> <td>6.63e-151</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>10:06:01</td>     <th>  Log-Likelihood:    </th> <td>  421.92</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   599</td>      <th>  AIC:               </th> <td>  -601.8</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   478</td>      <th>  BIC:               </th> <td>  -70.02</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>   121</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>      <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>   <td>    0.0012</td> <td>    0.002</td> <td>    0.552</td> <td> 0.581</td> <td>   -0.003</td> <td>    0.005</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>   <td>    0.1504</td> <td>    0.852</td> <td>    0.177</td> <td> 0.860</td> <td>   -1.524</td> <td>    1.825</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>   <td>   -0.1930</td> <td>    0.193</td> <td>   -0.999</td> <td> 0.318</td> <td>   -0.572</td> <td>    0.186</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>   <td>    0.1180</td> <td>    0.100</td> <td>    1.183</td> <td> 0.238</td> <td>   -0.078</td> <td>    0.314</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x5</th>   <td>   -0.0540</td> <td>    0.110</td> <td>   -0.493</td> <td> 0.622</td> <td>   -0.269</td> <td>    0.161</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x6</th>   <td>    0.0509</td> <td>    0.064</td> <td>    0.798</td> <td> 0.426</td> <td>   -0.075</td> <td>    0.176</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x7</th>   <td>    0.1650</td> <td>    0.113</td> <td>    1.454</td> <td> 0.147</td> <td>   -0.058</td> <td>    0.388</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x8</th>   <td>    0.2378</td> <td>    0.220</td> <td>    1.083</td> <td> 0.279</td> <td>   -0.194</td> <td>    0.669</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x9</th>   <td>    0.1906</td> <td>    0.299</td> <td>    0.637</td> <td> 0.525</td> <td>   -0.398</td> <td>    0.779</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x10</th>  <td>   -0.4994</td> <td>    0.313</td> <td>   -1.593</td> <td> 0.112</td> <td>   -1.115</td> <td>    0.117</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x11</th>  <td>    0.2046</td> <td>    0.193</td> <td>    1.061</td> <td> 0.289</td> <td>   -0.174</td> <td>    0.584</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x12</th>  <td>   -0.5443</td> <td>    0.779</td> <td>   -0.698</td> <td> 0.485</td> <td>   -2.076</td> <td>    0.987</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x13</th>  <td>    0.0553</td> <td>    0.031</td> <td>    1.755</td> <td> 0.080</td> <td>   -0.007</td> <td>    0.117</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x14</th>  <td>   -0.2696</td> <td>    0.364</td> <td>   -0.741</td> <td> 0.459</td> <td>   -0.985</td> <td>    0.445</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x15</th>  <td>   -0.3002</td> <td>    0.178</td> <td>   -1.688</td> <td> 0.092</td> <td>   -0.650</td> <td>    0.049</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x16</th>  <td>    0.0810</td> <td>    0.041</td> <td>    1.973</td> <td> 0.049</td> <td>    0.000</td> <td>    0.162</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x17</th>  <td>   -0.0542</td> <td>    0.122</td> <td>   -0.446</td> <td> 0.656</td> <td>   -0.293</td> <td>    0.185</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x18</th>  <td>    0.0003</td> <td>    0.215</td> <td>    0.001</td> <td> 0.999</td> <td>   -0.421</td> <td>    0.422</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x19</th>  <td>   -0.1479</td> <td>    0.092</td> <td>   -1.603</td> <td> 0.110</td> <td>   -0.329</td> <td>    0.033</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x20</th>  <td>   -0.0741</td> <td>    0.069</td> <td>   -1.071</td> <td> 0.285</td> <td>   -0.210</td> <td>    0.062</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x21</th>  <td>    0.5070</td> <td>    0.341</td> <td>    1.487</td> <td> 0.138</td> <td>   -0.163</td> <td>    1.177</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x22</th>  <td>    0.3407</td> <td>    0.398</td> <td>    0.855</td> <td> 0.393</td> <td>   -0.442</td> <td>    1.124</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x23</th>  <td>   -0.6287</td> <td>    0.298</td> <td>   -2.107</td> <td> 0.036</td> <td>   -1.215</td> <td>   -0.042</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x24</th>  <td>   -0.0713</td> <td>    0.051</td> <td>   -1.391</td> <td> 0.165</td> <td>   -0.172</td> <td>    0.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x25</th>  <td>    0.0134</td> <td>    0.039</td> <td>    0.347</td> <td> 0.729</td> <td>   -0.062</td> <td>    0.089</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x26</th>  <td>   -0.0035</td> <td>    0.035</td> <td>   -0.100</td> <td> 0.920</td> <td>   -0.071</td> <td>    0.064</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x27</th>  <td>    0.0575</td> <td>    0.037</td> <td>    1.562</td> <td> 0.119</td> <td>   -0.015</td> <td>    0.130</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x28</th>  <td>    0.0294</td> <td>    0.051</td> <td>    0.578</td> <td> 0.563</td> <td>   -0.070</td> <td>    0.129</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x29</th>  <td>    0.3430</td> <td>    0.431</td> <td>    0.796</td> <td> 0.426</td> <td>   -0.504</td> <td>    1.190</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x30</th>  <td>    0.0059</td> <td>    0.127</td> <td>    0.046</td> <td> 0.963</td> <td>   -0.244</td> <td>    0.256</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x31</th>  <td>   -0.0931</td> <td>    0.132</td> <td>   -0.703</td> <td> 0.483</td> <td>   -0.353</td> <td>    0.167</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x32</th>  <td>    0.0651</td> <td>    0.196</td> <td>    0.332</td> <td> 0.740</td> <td>   -0.320</td> <td>    0.450</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x33</th>  <td>    0.0865</td> <td>    0.156</td> <td>    0.556</td> <td> 0.579</td> <td>   -0.219</td> <td>    0.392</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x34</th>  <td>   -0.0279</td> <td>    0.086</td> <td>   -0.326</td> <td> 0.745</td> <td>   -0.196</td> <td>    0.140</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x35</th>  <td>    0.2193</td> <td>    0.175</td> <td>    1.252</td> <td> 0.211</td> <td>   -0.125</td> <td>    0.564</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x36</th>  <td>   -0.0265</td> <td>    0.062</td> <td>   -0.427</td> <td> 0.670</td> <td>   -0.148</td> <td>    0.095</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x37</th>  <td>   -0.0135</td> <td>    0.082</td> <td>   -0.166</td> <td> 0.869</td> <td>   -0.174</td> <td>    0.147</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x38</th>  <td>   -0.0092</td> <td>    0.113</td> <td>   -0.081</td> <td> 0.935</td> <td>   -0.231</td> <td>    0.213</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x39</th>  <td>    0.0909</td> <td>    0.169</td> <td>    0.537</td> <td> 0.591</td> <td>   -0.241</td> <td>    0.423</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x40</th>  <td>    0.5791</td> <td>    0.617</td> <td>    0.939</td> <td> 0.348</td> <td>   -0.633</td> <td>    1.791</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x41</th>  <td>    0.3570</td> <td>    0.134</td> <td>    2.658</td> <td> 0.008</td> <td>    0.093</td> <td>    0.621</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x42</th>  <td>    0.5875</td> <td>    0.817</td> <td>    0.719</td> <td> 0.473</td> <td>   -1.019</td> <td>    2.194</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x43</th>  <td>   -0.8671</td> <td>    1.358</td> <td>   -0.638</td> <td> 0.523</td> <td>   -3.536</td> <td>    1.801</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x44</th>  <td>   -0.4230</td> <td>    0.327</td> <td>   -1.294</td> <td> 0.196</td> <td>   -1.065</td> <td>    0.219</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x45</th>  <td>    0.5721</td> <td>    0.323</td> <td>    1.770</td> <td> 0.077</td> <td>   -0.063</td> <td>    1.207</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x46</th>  <td>   -0.6656</td> <td>    0.332</td> <td>   -2.003</td> <td> 0.046</td> <td>   -1.318</td> <td>   -0.013</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x47</th>  <td>   -0.1075</td> <td>    0.098</td> <td>   -1.103</td> <td> 0.271</td> <td>   -0.299</td> <td>    0.084</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x48</th>  <td>   -0.0370</td> <td>    0.087</td> <td>   -0.425</td> <td> 0.671</td> <td>   -0.208</td> <td>    0.134</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x49</th>  <td>    0.0059</td> <td>    0.097</td> <td>    0.060</td> <td> 0.952</td> <td>   -0.185</td> <td>    0.197</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x50</th>  <td>   -0.0857</td> <td>    0.111</td> <td>   -0.771</td> <td> 0.441</td> <td>   -0.304</td> <td>    0.133</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x51</th>  <td>   -0.4362</td> <td>    0.321</td> <td>   -1.357</td> <td> 0.175</td> <td>   -1.068</td> <td>    0.195</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x52</th>  <td>    0.1979</td> <td>    0.097</td> <td>    2.040</td> <td> 0.042</td> <td>    0.007</td> <td>    0.389</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x53</th>  <td>   -0.0694</td> <td>    0.220</td> <td>   -0.315</td> <td> 0.753</td> <td>   -0.502</td> <td>    0.363</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x54</th>  <td>    0.1370</td> <td>    0.076</td> <td>    1.797</td> <td> 0.073</td> <td>   -0.013</td> <td>    0.287</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x55</th>  <td>   -0.2583</td> <td>    0.138</td> <td>   -1.865</td> <td> 0.063</td> <td>   -0.530</td> <td>    0.014</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x56</th>  <td>    0.0520</td> <td>    0.172</td> <td>    0.303</td> <td> 0.762</td> <td>   -0.285</td> <td>    0.389</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x57</th>  <td>   -0.0009</td> <td>    0.124</td> <td>   -0.008</td> <td> 0.994</td> <td>   -0.244</td> <td>    0.242</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x58</th>  <td>   -0.1588</td> <td>    0.229</td> <td>   -0.694</td> <td> 0.488</td> <td>   -0.608</td> <td>    0.291</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x59</th>  <td>   -0.0690</td> <td>    0.430</td> <td>   -0.160</td> <td> 0.873</td> <td>   -0.915</td> <td>    0.777</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x60</th>  <td>    0.2131</td> <td>    0.546</td> <td>    0.390</td> <td> 0.697</td> <td>   -0.860</td> <td>    1.286</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x61</th>  <td>   -0.0901</td> <td>    0.422</td> <td>   -0.214</td> <td> 0.831</td> <td>   -0.918</td> <td>    0.738</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x62</th>  <td>    0.1674</td> <td>    0.144</td> <td>    1.163</td> <td> 0.245</td> <td>   -0.115</td> <td>    0.450</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x63</th>  <td>   -0.1834</td> <td>    0.140</td> <td>   -1.306</td> <td> 0.192</td> <td>   -0.459</td> <td>    0.092</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x64</th>  <td>    0.3565</td> <td>    0.472</td> <td>    0.756</td> <td> 0.450</td> <td>   -0.571</td> <td>    1.284</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x65</th>  <td>   -0.4619</td> <td>    0.502</td> <td>   -0.920</td> <td> 0.358</td> <td>   -1.449</td> <td>    0.525</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x66</th>  <td>    1.4853</td> <td>    0.514</td> <td>    2.891</td> <td> 0.004</td> <td>    0.476</td> <td>    2.495</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x67</th>  <td>   -0.3049</td> <td>    0.353</td> <td>   -0.863</td> <td> 0.388</td> <td>   -0.999</td> <td>    0.389</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x68</th>  <td>   -0.3544</td> <td>    0.153</td> <td>   -2.322</td> <td> 0.021</td> <td>   -0.654</td> <td>   -0.055</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x69</th>  <td>   -0.7536</td> <td>    0.742</td> <td>   -1.015</td> <td> 0.310</td> <td>   -2.212</td> <td>    0.705</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x70</th>  <td>    0.0610</td> <td>    0.179</td> <td>    0.341</td> <td> 0.734</td> <td>   -0.291</td> <td>    0.413</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x71</th>  <td>    0.0625</td> <td>    0.114</td> <td>    0.548</td> <td> 0.584</td> <td>   -0.162</td> <td>    0.287</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x72</th>  <td>   -0.0107</td> <td>    0.038</td> <td>   -0.280</td> <td> 0.780</td> <td>   -0.086</td> <td>    0.064</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x73</th>  <td>    0.0633</td> <td>    0.187</td> <td>    0.338</td> <td> 0.736</td> <td>   -0.305</td> <td>    0.432</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x74</th>  <td>   -0.1092</td> <td>    0.070</td> <td>   -1.550</td> <td> 0.122</td> <td>   -0.248</td> <td>    0.029</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x75</th>  <td>    0.5395</td> <td>    0.777</td> <td>    0.694</td> <td> 0.488</td> <td>   -0.988</td> <td>    2.067</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x76</th>  <td>   -0.0364</td> <td>    0.043</td> <td>   -0.845</td> <td> 0.399</td> <td>   -0.121</td> <td>    0.048</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x77</th>  <td>   -0.0911</td> <td>    0.052</td> <td>   -1.750</td> <td> 0.081</td> <td>   -0.193</td> <td>    0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x78</th>  <td>   -0.0044</td> <td>    0.057</td> <td>   -0.077</td> <td> 0.938</td> <td>   -0.116</td> <td>    0.107</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x79</th>  <td>    0.0453</td> <td>    0.071</td> <td>    0.639</td> <td> 0.523</td> <td>   -0.094</td> <td>    0.185</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x80</th>  <td>    0.0610</td> <td>    0.038</td> <td>    1.593</td> <td> 0.112</td> <td>   -0.014</td> <td>    0.136</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x81</th>  <td>   -0.2545</td> <td>    0.395</td> <td>   -0.644</td> <td> 0.520</td> <td>   -1.031</td> <td>    0.522</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x82</th>  <td>    0.0228</td> <td>    0.592</td> <td>    0.039</td> <td> 0.969</td> <td>   -1.140</td> <td>    1.186</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x83</th>  <td>    0.1220</td> <td>    0.341</td> <td>    0.358</td> <td> 0.721</td> <td>   -0.548</td> <td>    0.792</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x84</th>  <td>   -0.2215</td> <td>    0.122</td> <td>   -1.817</td> <td> 0.070</td> <td>   -0.461</td> <td>    0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x85</th>  <td>   -0.3281</td> <td>    0.309</td> <td>   -1.064</td> <td> 0.288</td> <td>   -0.934</td> <td>    0.278</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x86</th>  <td>   -0.1372</td> <td>    0.167</td> <td>   -0.824</td> <td> 0.410</td> <td>   -0.465</td> <td>    0.190</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x87</th>  <td>    0.6059</td> <td>    0.281</td> <td>    2.158</td> <td> 0.031</td> <td>    0.054</td> <td>    1.157</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x88</th>  <td>    0.0254</td> <td>    0.059</td> <td>    0.432</td> <td> 0.666</td> <td>   -0.090</td> <td>    0.141</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x89</th>  <td>   -0.0035</td> <td>    0.068</td> <td>   -0.051</td> <td> 0.959</td> <td>   -0.137</td> <td>    0.130</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x90</th>  <td>    0.0060</td> <td>    0.048</td> <td>    0.124</td> <td> 0.901</td> <td>   -0.089</td> <td>    0.101</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x91</th>  <td>    0.3126</td> <td>    0.153</td> <td>    2.045</td> <td> 0.041</td> <td>    0.012</td> <td>    0.613</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x92</th>  <td>    0.1602</td> <td>    0.115</td> <td>    1.398</td> <td> 0.163</td> <td>   -0.065</td> <td>    0.385</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x93</th>  <td>    0.4790</td> <td>    0.190</td> <td>    2.518</td> <td> 0.012</td> <td>    0.105</td> <td>    0.853</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x94</th>  <td>    0.0814</td> <td>    0.078</td> <td>    1.041</td> <td> 0.299</td> <td>   -0.072</td> <td>    0.235</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x95</th>  <td>    0.0191</td> <td>    0.109</td> <td>    0.175</td> <td> 0.861</td> <td>   -0.196</td> <td>    0.234</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x96</th>  <td>    0.0548</td> <td>    0.077</td> <td>    0.710</td> <td> 0.478</td> <td>   -0.097</td> <td>    0.206</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x97</th>  <td>   -0.0376</td> <td>    0.084</td> <td>   -0.447</td> <td> 0.655</td> <td>   -0.203</td> <td>    0.128</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x98</th>  <td>    0.9651</td> <td>    0.993</td> <td>    0.972</td> <td> 0.332</td> <td>   -0.987</td> <td>    2.917</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x99</th>  <td>    0.5435</td> <td>    0.584</td> <td>    0.930</td> <td> 0.353</td> <td>   -0.605</td> <td>    1.692</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x100</th> <td>    0.0875</td> <td>    0.211</td> <td>    0.415</td> <td> 0.678</td> <td>   -0.326</td> <td>    0.501</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x101</th> <td>   -1.5412</td> <td>    1.328</td> <td>   -1.160</td> <td> 0.246</td> <td>   -4.151</td> <td>    1.068</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x102</th> <td>   -0.1336</td> <td>    0.468</td> <td>   -0.285</td> <td> 0.776</td> <td>   -1.054</td> <td>    0.787</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x103</th> <td>    0.1613</td> <td>    0.424</td> <td>    0.380</td> <td> 0.704</td> <td>   -0.672</td> <td>    0.995</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x104</th> <td>    0.0057</td> <td>    0.230</td> <td>    0.025</td> <td> 0.980</td> <td>   -0.447</td> <td>    0.458</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x105</th> <td>    0.5435</td> <td>    0.584</td> <td>    0.930</td> <td> 0.353</td> <td>   -0.605</td> <td>    1.692</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x106</th> <td>   -0.1595</td> <td>    0.112</td> <td>   -1.420</td> <td> 0.156</td> <td>   -0.380</td> <td>    0.061</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x107</th> <td>    0.2134</td> <td>    0.216</td> <td>    0.988</td> <td> 0.324</td> <td>   -0.211</td> <td>    0.638</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x108</th> <td>   -0.1485</td> <td>    0.349</td> <td>   -0.426</td> <td> 0.670</td> <td>   -0.834</td> <td>    0.537</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x109</th> <td>   -0.4664</td> <td>    0.380</td> <td>   -1.227</td> <td> 0.221</td> <td>   -1.213</td> <td>    0.281</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x110</th> <td>    0.0946</td> <td>    0.123</td> <td>    0.767</td> <td> 0.443</td> <td>   -0.148</td> <td>    0.337</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x111</th> <td>    0.5037</td> <td>    0.473</td> <td>    1.065</td> <td> 0.287</td> <td>   -0.425</td> <td>    1.433</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x112</th> <td>   -0.1287</td> <td>    0.603</td> <td>   -0.213</td> <td> 0.831</td> <td>   -1.314</td> <td>    1.056</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x113</th> <td>   -0.1022</td> <td>    0.106</td> <td>   -0.965</td> <td> 0.335</td> <td>   -0.310</td> <td>    0.106</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x114</th> <td>   -0.1244</td> <td>    0.092</td> <td>   -1.354</td> <td> 0.176</td> <td>   -0.305</td> <td>    0.056</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x115</th> <td>   -0.0867</td> <td>    0.091</td> <td>   -0.957</td> <td> 0.339</td> <td>   -0.265</td> <td>    0.091</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x116</th> <td>   -0.0567</td> <td>    0.062</td> <td>   -0.914</td> <td> 0.361</td> <td>   -0.179</td> <td>    0.065</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x117</th> <td>   -0.0571</td> <td>    0.047</td> <td>   -1.219</td> <td> 0.223</td> <td>   -0.149</td> <td>    0.035</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x118</th> <td>    0.5110</td> <td>    0.254</td> <td>    2.011</td> <td> 0.045</td> <td>    0.012</td> <td>    1.010</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x119</th> <td>   -0.6915</td> <td>    0.954</td> <td>   -0.725</td> <td> 0.469</td> <td>   -2.566</td> <td>    1.183</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x120</th> <td>    0.0148</td> <td>    0.176</td> <td>    0.084</td> <td> 0.933</td> <td>   -0.331</td> <td>    0.360</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x121</th> <td>    0.0787</td> <td>    0.049</td> <td>    1.611</td> <td> 0.108</td> <td>   -0.017</td> <td>    0.175</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x122</th> <td>   -0.0108</td> <td>    0.086</td> <td>   -0.125</td> <td> 0.900</td> <td>   -0.181</td> <td>    0.159</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>106.520</td> <th>  Durbin-Watson:     </th> <td>   2.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 332.631</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.837</td>  <th>  Prob(JB):          </th> <td>5.89e-73</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 6.244</td>  <th>  Cond. No.          </th> <td>1.17e+16</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.868\n",
       "Model:                            OLS   Adj. R-squared:                  0.834\n",
       "Method:                 Least Squares   F-statistic:                     25.94\n",
       "Date:                Mon, 03 Jul 2017   Prob (F-statistic):          6.63e-151\n",
       "Time:                        10:06:01   Log-Likelihood:                 421.92\n",
       "No. Observations:                 599   AIC:                            -601.8\n",
       "Df Residuals:                     478   BIC:                            -70.02\n",
       "Df Model:                         121                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "x1             0.0012      0.002      0.552      0.581      -0.003       0.005\n",
       "x2             0.1504      0.852      0.177      0.860      -1.524       1.825\n",
       "x3            -0.1930      0.193     -0.999      0.318      -0.572       0.186\n",
       "x4             0.1180      0.100      1.183      0.238      -0.078       0.314\n",
       "x5            -0.0540      0.110     -0.493      0.622      -0.269       0.161\n",
       "x6             0.0509      0.064      0.798      0.426      -0.075       0.176\n",
       "x7             0.1650      0.113      1.454      0.147      -0.058       0.388\n",
       "x8             0.2378      0.220      1.083      0.279      -0.194       0.669\n",
       "x9             0.1906      0.299      0.637      0.525      -0.398       0.779\n",
       "x10           -0.4994      0.313     -1.593      0.112      -1.115       0.117\n",
       "x11            0.2046      0.193      1.061      0.289      -0.174       0.584\n",
       "x12           -0.5443      0.779     -0.698      0.485      -2.076       0.987\n",
       "x13            0.0553      0.031      1.755      0.080      -0.007       0.117\n",
       "x14           -0.2696      0.364     -0.741      0.459      -0.985       0.445\n",
       "x15           -0.3002      0.178     -1.688      0.092      -0.650       0.049\n",
       "x16            0.0810      0.041      1.973      0.049       0.000       0.162\n",
       "x17           -0.0542      0.122     -0.446      0.656      -0.293       0.185\n",
       "x18            0.0003      0.215      0.001      0.999      -0.421       0.422\n",
       "x19           -0.1479      0.092     -1.603      0.110      -0.329       0.033\n",
       "x20           -0.0741      0.069     -1.071      0.285      -0.210       0.062\n",
       "x21            0.5070      0.341      1.487      0.138      -0.163       1.177\n",
       "x22            0.3407      0.398      0.855      0.393      -0.442       1.124\n",
       "x23           -0.6287      0.298     -2.107      0.036      -1.215      -0.042\n",
       "x24           -0.0713      0.051     -1.391      0.165      -0.172       0.029\n",
       "x25            0.0134      0.039      0.347      0.729      -0.062       0.089\n",
       "x26           -0.0035      0.035     -0.100      0.920      -0.071       0.064\n",
       "x27            0.0575      0.037      1.562      0.119      -0.015       0.130\n",
       "x28            0.0294      0.051      0.578      0.563      -0.070       0.129\n",
       "x29            0.3430      0.431      0.796      0.426      -0.504       1.190\n",
       "x30            0.0059      0.127      0.046      0.963      -0.244       0.256\n",
       "x31           -0.0931      0.132     -0.703      0.483      -0.353       0.167\n",
       "x32            0.0651      0.196      0.332      0.740      -0.320       0.450\n",
       "x33            0.0865      0.156      0.556      0.579      -0.219       0.392\n",
       "x34           -0.0279      0.086     -0.326      0.745      -0.196       0.140\n",
       "x35            0.2193      0.175      1.252      0.211      -0.125       0.564\n",
       "x36           -0.0265      0.062     -0.427      0.670      -0.148       0.095\n",
       "x37           -0.0135      0.082     -0.166      0.869      -0.174       0.147\n",
       "x38           -0.0092      0.113     -0.081      0.935      -0.231       0.213\n",
       "x39            0.0909      0.169      0.537      0.591      -0.241       0.423\n",
       "x40            0.5791      0.617      0.939      0.348      -0.633       1.791\n",
       "x41            0.3570      0.134      2.658      0.008       0.093       0.621\n",
       "x42            0.5875      0.817      0.719      0.473      -1.019       2.194\n",
       "x43           -0.8671      1.358     -0.638      0.523      -3.536       1.801\n",
       "x44           -0.4230      0.327     -1.294      0.196      -1.065       0.219\n",
       "x45            0.5721      0.323      1.770      0.077      -0.063       1.207\n",
       "x46           -0.6656      0.332     -2.003      0.046      -1.318      -0.013\n",
       "x47           -0.1075      0.098     -1.103      0.271      -0.299       0.084\n",
       "x48           -0.0370      0.087     -0.425      0.671      -0.208       0.134\n",
       "x49            0.0059      0.097      0.060      0.952      -0.185       0.197\n",
       "x50           -0.0857      0.111     -0.771      0.441      -0.304       0.133\n",
       "x51           -0.4362      0.321     -1.357      0.175      -1.068       0.195\n",
       "x52            0.1979      0.097      2.040      0.042       0.007       0.389\n",
       "x53           -0.0694      0.220     -0.315      0.753      -0.502       0.363\n",
       "x54            0.1370      0.076      1.797      0.073      -0.013       0.287\n",
       "x55           -0.2583      0.138     -1.865      0.063      -0.530       0.014\n",
       "x56            0.0520      0.172      0.303      0.762      -0.285       0.389\n",
       "x57           -0.0009      0.124     -0.008      0.994      -0.244       0.242\n",
       "x58           -0.1588      0.229     -0.694      0.488      -0.608       0.291\n",
       "x59           -0.0690      0.430     -0.160      0.873      -0.915       0.777\n",
       "x60            0.2131      0.546      0.390      0.697      -0.860       1.286\n",
       "x61           -0.0901      0.422     -0.214      0.831      -0.918       0.738\n",
       "x62            0.1674      0.144      1.163      0.245      -0.115       0.450\n",
       "x63           -0.1834      0.140     -1.306      0.192      -0.459       0.092\n",
       "x64            0.3565      0.472      0.756      0.450      -0.571       1.284\n",
       "x65           -0.4619      0.502     -0.920      0.358      -1.449       0.525\n",
       "x66            1.4853      0.514      2.891      0.004       0.476       2.495\n",
       "x67           -0.3049      0.353     -0.863      0.388      -0.999       0.389\n",
       "x68           -0.3544      0.153     -2.322      0.021      -0.654      -0.055\n",
       "x69           -0.7536      0.742     -1.015      0.310      -2.212       0.705\n",
       "x70            0.0610      0.179      0.341      0.734      -0.291       0.413\n",
       "x71            0.0625      0.114      0.548      0.584      -0.162       0.287\n",
       "x72           -0.0107      0.038     -0.280      0.780      -0.086       0.064\n",
       "x73            0.0633      0.187      0.338      0.736      -0.305       0.432\n",
       "x74           -0.1092      0.070     -1.550      0.122      -0.248       0.029\n",
       "x75            0.5395      0.777      0.694      0.488      -0.988       2.067\n",
       "x76           -0.0364      0.043     -0.845      0.399      -0.121       0.048\n",
       "x77           -0.0911      0.052     -1.750      0.081      -0.193       0.011\n",
       "x78           -0.0044      0.057     -0.077      0.938      -0.116       0.107\n",
       "x79            0.0453      0.071      0.639      0.523      -0.094       0.185\n",
       "x80            0.0610      0.038      1.593      0.112      -0.014       0.136\n",
       "x81           -0.2545      0.395     -0.644      0.520      -1.031       0.522\n",
       "x82            0.0228      0.592      0.039      0.969      -1.140       1.186\n",
       "x83            0.1220      0.341      0.358      0.721      -0.548       0.792\n",
       "x84           -0.2215      0.122     -1.817      0.070      -0.461       0.018\n",
       "x85           -0.3281      0.309     -1.064      0.288      -0.934       0.278\n",
       "x86           -0.1372      0.167     -0.824      0.410      -0.465       0.190\n",
       "x87            0.6059      0.281      2.158      0.031       0.054       1.157\n",
       "x88            0.0254      0.059      0.432      0.666      -0.090       0.141\n",
       "x89           -0.0035      0.068     -0.051      0.959      -0.137       0.130\n",
       "x90            0.0060      0.048      0.124      0.901      -0.089       0.101\n",
       "x91            0.3126      0.153      2.045      0.041       0.012       0.613\n",
       "x92            0.1602      0.115      1.398      0.163      -0.065       0.385\n",
       "x93            0.4790      0.190      2.518      0.012       0.105       0.853\n",
       "x94            0.0814      0.078      1.041      0.299      -0.072       0.235\n",
       "x95            0.0191      0.109      0.175      0.861      -0.196       0.234\n",
       "x96            0.0548      0.077      0.710      0.478      -0.097       0.206\n",
       "x97           -0.0376      0.084     -0.447      0.655      -0.203       0.128\n",
       "x98            0.9651      0.993      0.972      0.332      -0.987       2.917\n",
       "x99            0.5435      0.584      0.930      0.353      -0.605       1.692\n",
       "x100           0.0875      0.211      0.415      0.678      -0.326       0.501\n",
       "x101          -1.5412      1.328     -1.160      0.246      -4.151       1.068\n",
       "x102          -0.1336      0.468     -0.285      0.776      -1.054       0.787\n",
       "x103           0.1613      0.424      0.380      0.704      -0.672       0.995\n",
       "x104           0.0057      0.230      0.025      0.980      -0.447       0.458\n",
       "x105           0.5435      0.584      0.930      0.353      -0.605       1.692\n",
       "x106          -0.1595      0.112     -1.420      0.156      -0.380       0.061\n",
       "x107           0.2134      0.216      0.988      0.324      -0.211       0.638\n",
       "x108          -0.1485      0.349     -0.426      0.670      -0.834       0.537\n",
       "x109          -0.4664      0.380     -1.227      0.221      -1.213       0.281\n",
       "x110           0.0946      0.123      0.767      0.443      -0.148       0.337\n",
       "x111           0.5037      0.473      1.065      0.287      -0.425       1.433\n",
       "x112          -0.1287      0.603     -0.213      0.831      -1.314       1.056\n",
       "x113          -0.1022      0.106     -0.965      0.335      -0.310       0.106\n",
       "x114          -0.1244      0.092     -1.354      0.176      -0.305       0.056\n",
       "x115          -0.0867      0.091     -0.957      0.339      -0.265       0.091\n",
       "x116          -0.0567      0.062     -0.914      0.361      -0.179       0.065\n",
       "x117          -0.0571      0.047     -1.219      0.223      -0.149       0.035\n",
       "x118           0.5110      0.254      2.011      0.045       0.012       1.010\n",
       "x119          -0.6915      0.954     -0.725      0.469      -2.566       1.183\n",
       "x120           0.0148      0.176      0.084      0.933      -0.331       0.360\n",
       "x121           0.0787      0.049      1.611      0.108      -0.017       0.175\n",
       "x122          -0.0108      0.086     -0.125      0.900      -0.181       0.159\n",
       "==============================================================================\n",
       "Omnibus:                      106.520   Durbin-Watson:                   2.001\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              332.631\n",
       "Skew:                           0.837   Prob(JB):                     5.89e-73\n",
       "Kurtosis:                       6.244   Cond. No.                     1.17e+16\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 2.22e-28. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_m(np.asarray(y_test), np.asarray(x_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Multivariate Linear Regression with Sk Learn\"\"\"\n",
    "\n",
    "multi_regression_model = LinearRegression(fit_intercept=True)\n",
    "multi_regression_model.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# print ('The equation of the regression plane is: {} + {}^T . x'.format(multi_regression_model.intercept_, multi_regression_model.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train MSE is 0.015565029548165632, the test MSE is 0.019588942468657618\n",
      "The train R^2 is 0.7144096927883362, the test R^2 is 0.6349076121953976\n"
     ]
    }
   ],
   "source": [
    "train_MSE = np.mean((y_train - multi_regression_model.predict(x_train))**2)\n",
    "test_MSE = np.mean((y_test - multi_regression_model.predict(x_test))**2)\n",
    "print ('The train MSE is {}, the test MSE is {}'.format(train_MSE, test_MSE))\n",
    "\n",
    "train_R_sq = multi_regression_model.score(x_train, y_train)\n",
    "test_R_sq = multi_regression_model.score(x_test, y_test)\n",
    "print ('The train R^2 is {}, the test R^2 is {}'.format(train_R_sq, test_R_sq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_regression = Lasso(alpha=1.0, fit_intercept=True)\n",
    "lasso_regression.fit(x_train, y_train)\n",
    "\n",
    "# print ('Lasso regression model:\\n {} + {}^T . x'.format(lasso_regression.intercept_, lasso_regression.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R^2: -6.155794394180347e-05, test R^2: -0.0006897794585958295\n"
     ]
    }
   ],
   "source": [
    "print ('Train R^2: {}, test R^2: {}'.format(lasso_regression.score(np.vstack((x_train, x_test)), \n",
    "                                                                  np.hstack((y_train, y_test))), \n",
    "                                           lasso_regression.score(x_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Bayesian Linear Model\"\"\"\n",
    "ridge_regression = Ridge(alpha=1.0, fit_intercept=True)\n",
    "ridge_regression.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge regression model:\n",
      " 0.48962144510797845 + [-0.00311588 -0.01370701  0.03453485  0.17269124 -0.06118889 -0.04058791\n",
      "  0.05757644  0.02814591 -0.1374883  -0.03773884  0.0533982  -0.04256141\n",
      "  0.04206455  0.01440109 -0.09613034  0.03047961 -0.14103253  0.07411475\n",
      "  0.0745855  -0.07675979  0.06164042 -0.01788982 -0.09136161 -0.01795817\n",
      " -0.03176355  0.03529603  0.03323476  0.0214208  -0.03605888 -0.14435592\n",
      " -0.06219248  0.0230347   0.02677167 -0.01048314  0.15229672 -0.07640003\n",
      " -0.02116676  0.09379819  0.03392519  0.14335343  0.08074673 -0.11442319\n",
      " -0.01748127  0.03325217 -0.11944969 -0.17649234 -0.01269797 -0.01815765\n",
      "  0.04616793 -0.16374757 -0.07713859  0.12662985 -0.08737211 -0.01536171\n",
      "  0.0616001  -0.02522851  0.00245863  0.00309001  0.00472387  0.06632188\n",
      " -0.00884749 -0.05104666 -0.1297033  -0.09258352 -0.05090585  0.12210806\n",
      " -0.00591309 -0.01280217 -0.05684528  0.11970454  0.10975321  0.01998404\n",
      "  0.14356558 -0.04387085  0.02159484  0.09316402 -0.05359395  0.0011874\n",
      " -0.00677122 -0.04160921 -0.05096789  0.02426551  0.00137903 -0.18552803\n",
      "  0.04596957  0.0220203   0.15090743  0.08099073 -0.05536877 -0.10235686\n",
      "  0.07233842  0.13585066  0.0275844   0.02335524 -0.01806301  0.02457513\n",
      " -0.01031984  0.00051167  0.00912943  0.03412742  0.06257904 -0.04972559\n",
      "  0.06794001  0.08265488  0.01061495 -0.08547601 -0.04176511 -0.00576047\n",
      "  0.08766362  0.03476376 -0.00836525  0.02873748  0.04606421 -0.0162174\n",
      "  0.06173292  0.00290231 -0.01629274  0.0447862   0.03337019  0.0386569\n",
      "  0.01520888 -0.0626122 ]^T . x\n"
     ]
    }
   ],
   "source": [
    "print ('Ridge regression model:\\n {} + {}^T . x'.format(ridge_regression.intercept_, ridge_regression.coef_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train R^2: 0.7075383072145718\n"
     ]
    }
   ],
   "source": [
    "print ('Train R^2: {}'.format(ridge_regression.score(x_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.0, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gen_cross_terms = PolynomialFeatures(interaction_only=True)\n",
    "cross_terms = gen_cross_terms.fit_transform(x_train)\n",
    "X_train_with_cross = np.hstack((x_train, cross_terms))\n",
    "cross_terms = gen_cross_terms.fit_transform(x_test)\n",
    "X_test_with_cross = np.hstack((x_test, cross_terms))\n",
    "\n",
    "ridge_regression_inter = Ridge(alpha=1.0, fit_intercept=True)\n",
    "ridge_regression_inter.fit(X_train_with_cross, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train MSE with interaction terms is 0.004815863756915889, the test MSE is 0.027020815744604514\n",
      "The train R^2 with interaction terms is 0.9116375586971361, the test R^2 is 0.4963947565617667\n"
     ]
    }
   ],
   "source": [
    "train_MSE = np.mean((y_train - ridge_regression_inter.predict(X_train_with_cross))**2)\n",
    "test_MSE = np.mean((y_test - ridge_regression_inter.predict(X_test_with_cross))**2)\n",
    "print ('The train MSE with interaction terms is {}, the test MSE is {}'.format(train_MSE, test_MSE))\n",
    "\n",
    "train_R_sq = ridge_regression_inter.score(X_train_with_cross, y_train)\n",
    "test_R_sq = ridge_regression_inter.score(X_test_with_cross, y_test)\n",
    "print ('The train R^2 with interaction terms is {}, the test R^2 is {}'.format(train_R_sq, test_R_sq))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficients: [-0.00282958 -0.01764647  0.02735676  0.13101422 -0.0887591  -0.03451273\n",
      "  0.02610715 -0.00105841 -0.09542232 -0.01975759  0.0338053  -0.02263707\n",
      "  0.03530196  0.02091088 -0.04779343  0.01360135 -0.11347512  0.04500072\n",
      "  0.05056976 -0.05784586  0.02444603 -0.01297944 -0.01899006 -0.01522693\n",
      " -0.02882245  0.03278412  0.03054946  0.02013634 -0.03845903 -0.07103396\n",
      " -0.03274838  0.02066972 -0.00630523 -0.01596874  0.07108964 -0.04794767\n",
      " -0.00321634  0.05000884 -0.00854012  0.08075115  0.0421138  -0.04282217\n",
      "  0.00911677  0.03055174 -0.09205087 -0.11831035 -0.03723887 -0.03828384\n",
      "  0.01622954 -0.10068473 -0.03857002  0.12883927 -0.10735009 -0.00559712\n",
      "  0.03163824 -0.00772097  0.00346861  0.00379681  0.01122422  0.02379166\n",
      "  0.01446734 -0.01332552 -0.05184277 -0.03105414 -0.02989438  0.05228861\n",
      " -0.00692883  0.00066065 -0.02348562  0.06294017  0.07217971  0.01143333\n",
      "  0.10919562 -0.05133825  0.00452947  0.08575933 -0.04187844  0.00487608\n",
      " -0.0024736  -0.03753008 -0.01215816  0.00387539 -0.00017624 -0.0857182\n",
      "  0.02412668  0.02690284  0.06256259  0.07061716 -0.03386253 -0.09067892\n",
      "  0.06979097  0.14067643  0.0166883   0.01224703 -0.00511809  0.02468308\n",
      " -0.00891512 -0.05522662 -0.00098167  0.00333114  0.05811345 -0.06683263\n",
      "  0.10121232  0.05658942  0.00028417 -0.05003384 -0.01810945  0.01242013\n",
      "  0.09669274  0.03145714 -0.00446996  0.03921906  0.02786813 -0.01479116\n",
      "  0.06218104  0.00734018 -0.0023502   0.05502876  0.06714933  0.02288204\n",
      "  0.01411278 -0.04013067], Precision of Weights: 4.5895199440047865\n"
     ]
    }
   ],
   "source": [
    "bay_reg = BayesianRidge(fit_intercept=True, normalize=True)\n",
    "bay_reg.fit(x_train, y_train)\n",
    "print ('Coefficients: {}, Precision of Weights: {}'.format(bay_reg.coef_, bay_reg.lambda_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, compute_score=False, copy_X=True,\n",
       "       fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06, n_iter=300,\n",
       "       normalize=True, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bay_reg_inter = BayesianRidge(fit_intercept=True, normalize=True)\n",
    "bay_reg_inter.fit(X_train_with_cross, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The train MSE with interaction terms is 0.01318400253266043, the test MSE is 0.019337874339600433\n",
      "The train R^2 with interaction terms is 0.7580972575779281, the test R^2 is 0.6395869389577162\n"
     ]
    }
   ],
   "source": [
    "train_MSE = np.mean((y_train - bay_reg_inter.predict(X_train_with_cross))**2)\n",
    "test_MSE = np.mean((y_test - bay_reg_inter.predict(X_test_with_cross))**2)\n",
    "print ('The train MSE with interaction terms is {}, the test MSE is {}'.format(train_MSE, test_MSE))\n",
    "\n",
    "train_R_sq = bay_reg_inter.score(X_train_with_cross, y_train)\n",
    "test_R_sq = bay_reg_inter.score(X_test_with_cross, y_test)\n",
    "print ('The train R^2 with interaction terms is {}, the test R^2 is {}'.format(train_R_sq, test_R_sq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
